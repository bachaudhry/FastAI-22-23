{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a90cd78-6177-4c1d-b213-dd9daf3039d9",
   "metadata": {},
   "source": [
    "# Matrix Multiplication From the Foundations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a33a8f-6ca5-4de1-b73a-ff9f02f8d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba52d1-ac48-457d-a392-96f3abdef04f",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88812f16-3150-4f07-a5da-497874a6342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the MNIST dataset with additional checks\n",
    "MNIST_URL = 'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
    "path_data = Path('data')\n",
    "\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1c049-0fa7-4fa2-9424-70e03d73040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196aaa6f-cef8-4bbd-ab6a-14d7bd7f3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking the location of download\n",
    "!ls -l data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb7f96-e870-4275-8050-72a5da31acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data as a tuple of tuples\n",
    "with gzip.open(path_gz, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63318f6-e2ad-497a-971a-8e3424cc4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5986c3-0c26-4ee1-a31e-61d48a684ea2",
   "metadata": {},
   "source": [
    "We aren't allowed to use Numpy, Pandas, PyTorch this early on, we'll have to work with the standard Python toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33748d2c-6812-4217-9099-02f628a7c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_1 = list(x_train[0])\n",
    "vals = lst_1[200:222]\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc056d03-60c3-460c-b982-5f11b0d0c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lst_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e072bf-00b6-4968-a571-16690d9ebbb9",
   "metadata": {},
   "source": [
    "Since we can't work with matrices at the moment, we will need to convert our list of 784 elements into lists of 28x28. To do that, we can use `chunks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561b7c6-f66f-4872-bc4f-8ae50d29bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for chunks\n",
    "def chunks(x, sz):\n",
    "    # Loop through values from 0 to length of the list based on size\n",
    "    # Yield(iterator) allows us to keep returning values till all elements in the\n",
    "    # input have finished.\n",
    "    for i in range(0, len(x), sz): yield x[i:i + sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f7b56-da5f-45bb-92e6-ea7fd852e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(chunks(vals, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68d237-e29f-48ea-9fd7-199edb1833b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "plt.imshow(list(chunks(lst_1, 28)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9393fe5-de25-4d1c-889e-87a32044bd4e",
   "metadata": {},
   "source": [
    "We can continue working with iterators using the library `itertools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92eb68-caa5-41aa-b955-2a1ccbc33f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f32a5-9bd5-41fc-ae22-03823f1d925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(vals)\n",
    "islice(it, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f916e57-f5ac-458f-b777-bf314175aa14",
   "metadata": {},
   "source": [
    "`islice` allows us to move through our data chunks based on the step value. Once there is no more data remaining in the chunks, it will return an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f1e07-e4d6-43dd-b0e9-b89a037b3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(islice(it, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54289bdc-4741-4d57-a08e-f500cc470819",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(islice(it, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bfab0d-1ef9-4f93-a6ff-3cf356448140",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(islice(it, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1f7ce-6045-4a9a-b299-ee41ce41c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(islice(it, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cfab7-d8c2-43f0-8c77-d942bf6e06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(islice(it, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352d47f-6f5a-47a0-b891-281affd5dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(islice(it, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5ec8f-1ee7-4f96-a9c0-2e4cea0331d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(lst_1)\n",
    "img = list(iter(lambda: list(islice(it, 28)), []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29387e-a2b7-4f36-bd6e-3bac278760a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022dd602-1bda-43ae-9c9c-96ccef6f7d88",
   "metadata": {},
   "source": [
    "## Creating a Matrix and Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1675681-58a0-4054-a0c5-00259d44a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing into an image for demo purposes\n",
    "img[20][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a3167-8450-4b17-871e-b27bbfe6b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a class to work with matrices\n",
    "# At first, this will only return the first and second indeces of an image\n",
    "class Matrix:\n",
    "    def __init__(self, xs): self.xs = xs\n",
    "    def __getitem__(self, idxs): return self.xs[idxs[0]][idxs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe754d4-79e7-4980-938d-fa008a8b3b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "m = Matrix(img)\n",
    "m[20, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61295b9-5668-43ce-9d45-588be3258c5b",
   "metadata": {},
   "source": [
    "We are now allowed to use the PyTorch `tensor` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419daa6-6600-4193-95d9-f71614ab0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2318587-bed0-4387-83a3-e144c1d0752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a1cc3-cac7-4772-8728-55c718802003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading image to Tensor\n",
    "tens = tensor(img)\n",
    "tens.shape, tens[20, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6ce7a-23b1-49d0-9e15-356e7dcb3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping train and valid to a tensor\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ad4ed-8977-4d61-9c8c-d539b0725781",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = x_train.reshape((-1, 28, 28))\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51498316-fad1-48e2-9577-bfe152bb879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9a3f7-d5bb-47d3-bb4f-d20f9f3a32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing into our tensor\n",
    "imgs[0, 20, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b6db0-a1f4-46b0-9fcf-7cd7a89025cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs, cols = x_train.shape\n",
    "y_train, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af6ab1-0fc6-4a69-bc14-a28130201aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time min(y_train), max(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f763068-39c3-4310-9eeb-f0ee6d2e53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e183b-5064-43bb-81e1-c463bd1789ac",
   "metadata": {},
   "source": [
    "## On Random Numbers\n",
    "\n",
    "Although we can use the random number generator in Python, we will opt to do it the hard way. \n",
    "\n",
    "This is based on the **Wichmann Hill** algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c8ff13-cdc4-4e36-8e42-e82781447fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our custom pseudo random number generator\n",
    "rnd_state = None\n",
    "def seed(a):\n",
    "    global rnd_state\n",
    "    a, x = divmod(a, 30268)\n",
    "    a, y = divmod(a, 30306)\n",
    "    a, z = divmod(a, 30322)\n",
    "    rnd_state = int(x) + 1, int(y) + 1, int(z) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b1d82-2b8a-481d-ae72-f6c8ae5087db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "seed(91737649164947)\n",
    "rnd_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513fefa-738c-422e-abb6-78fe88a618f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand():\n",
    "    global rnd_state\n",
    "    x, y, z = rnd_state\n",
    "    x = (171 * x) % 30269\n",
    "    y = (172 * y) % 30307\n",
    "    z = (170 * z) % 30323\n",
    "    rnd_state = x, y, z\n",
    "    return (x / 30269 + y / 30307 + z / 30323) % 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb044d8-0315-4be7-9c29-551c98151297",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand(), rand(), rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a1797-8bd0-41c3-a5e1-c1c1180a3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fork's a process, which returns 0 in the child and the child's process id\n",
    "# in the parent. \n",
    "# Right now, we are seeing similar random numbers because both the parent and the child\n",
    "# are copies of each other.\n",
    "if os.fork(): \n",
    "    print(f'In parent: {rand()}')\n",
    "else:\n",
    "    print(f'In child: {rand()}')\n",
    "    os._exit(os.EX_OK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5fdee-162f-425e-9198-460d7864887c",
   "metadata": {},
   "source": [
    "Let's see whether our go to libraries correctly re-initialize the random stream in the forked versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0941722-99ff-4aa7-b639-a975c446ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking PyTorch's version.\n",
    "import torch\n",
    "if os.fork(): \n",
    "    print(f'In parent: {torch.rand(1)}')\n",
    "else:\n",
    "    print(f'In child: {torch.rand(1)}')\n",
    "    os._exit(os.EX_OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bc88d-d999-486b-9e2c-defa0a6848db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Numpy\n",
    "import numpy as np\n",
    "if os.fork(): \n",
    "    print(f'In parent: {np.random.rand(1)}')\n",
    "else:\n",
    "    print(f'In child: {np.random.rand(1)}')\n",
    "    os._exit(os.EX_OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1076e6-cbf8-4284-b7b4-de891708a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking base Python\n",
    "from random import random\n",
    "if os.fork(): \n",
    "    print(f'In parent: {random()}')\n",
    "else:\n",
    "    print(f'In child: {random()}')\n",
    "    os._exit(os.EX_OK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d78fc-c9fa-4c7c-99d9-c07b8242ac79",
   "metadata": {},
   "source": [
    "Python's implementation is the only one that gets it right!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596215f6-0d65-49e9-ae0e-6112df2cf7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([rand() for _ in range(100)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6ac60-6211-4304-adc3-c029448132d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([rand() for _ in range(10000)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a083e7-0258-40af-ab5a-f51dda74daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 list(chunks([rand() for _ in range(7840)], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6c701-0c34-4334-ad7a-84026de2c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 torch.randn(784, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebd2d6-bcbc-445f-a96d-d2dd54c5ddc9",
   "metadata": {},
   "source": [
    "## Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27737b-a269-4ff3-8a69-7824e46d65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change torch display settings\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4593b4b-1a6e-4234-9983-172a57ef1a39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "# Creating random numbers for the weights\n",
    "weights = torch.randn(784, 10)\n",
    "bias = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d816e8-6e93-4dfe-9dde-6f24aafee3c6",
   "metadata": {},
   "source": [
    "`m1` will be a subset of the first 5 digits, on which we will carry out matrix multiplication operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff27840-7a26-4fbb-9255-5a6e5071421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = x_valid[:5] # This will give us 5 rows of 5 images which have been flattened out.\n",
    "m2 = weights\n",
    "\n",
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa4c63-09e4-442c-aa7e-ae7589382b77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ar, ac = m1.shape\n",
    "br, bc = m2.shape\n",
    "\n",
    "(ar, ac), (br, bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff70958-74bb-456c-96af-eb70f6e87be4",
   "metadata": {},
   "source": [
    "Carrying out a matrix multiplication on `5x784` and `784x10` will give us a resulting tensor of `5x10` which is the outcome of multiplying and adding 784 pairs of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e52b9-e660-44ff-8823-f16044dc0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty 5x10 tensor.\n",
    "t1 = torch.zeros(ar, bc)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a242973-a311-4542-bfe4-2af3968c2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a912ab-c529-44a5-ba82-37703fc9305c",
   "metadata": {},
   "source": [
    "Now, for the matrix multiplication itself, we will need to create nested loops which will add results of the matrix multiplication to the newly created tensor `t1`:\n",
    "1. Loop through each row from `m1`\n",
    "2. Loop through each column from `m2`\n",
    "3. Loop through each pair from `m1` and `m2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291cd429-3b7f-4d48-bd58-2e72c60bd10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ar): # Each row in m1       ----> 5\n",
    "    for j in range(bc): # Each column in m2----> 10\n",
    "        for k in range(ac): # Each pair    ----> 784\n",
    "            t1[i, j] += m1[i, k] * m2[k, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba09ba-4bc3-4693-b2e1-4e693849c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c932f-4201-4fc5-8faf-e4c9d8850215",
   "metadata": {},
   "source": [
    "Lets put this into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e8bcc-d098-4f78-a7b6-57b1f73ce8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    (ar, ac), (br, bc) = a.shape, b.shape \n",
    "    # Creating an empty 5x10 tensor.\n",
    "    c = torch.zeros(ar, bc)\n",
    "    # Run multiplication loops\n",
    "    for i in range(ar): # Each row in m1       ----> 5\n",
    "        for j in range(bc): # Each column in m2----> 10\n",
    "            for k in range(ac): # Each pair    ----> 784\n",
    "                c[i, j] += a[i, k] * b[k, j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e5d15-8e0c-470a-9ece-6b68f2c507aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77027d3c-d059-4b4c-8522-7e2d133d36f5",
   "metadata": {},
   "source": [
    "That is unacceptably slow for just..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac3b6d1-5e6e-4c0b-b5bb-127a5122b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar*bc*ac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541257b7-f19f-4ef1-b4fb-eebf1df0a3eb",
   "metadata": {},
   "source": [
    "..items, imagine running this kind of function on hundreds of thousands or millions of images.\n",
    "\n",
    "This is why we need to leverage libraries which can allow us to program in Python - but can compile our operations at considerably faster speeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe438c5-e28b-4d03-8037-a8cb2dbc3387",
   "metadata": {},
   "source": [
    "## Introducing `Numba` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96078fb1-213d-47a8-9dd2-41bb81f67df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06177d7b-0b56-4f98-ab6f-dc4cf77e1237",
   "metadata": {},
   "source": [
    "Based on the documentation, Numba is a JIT compiler for Python and is tailor made for code that utilizes NumPy arrays, functions and loops.\n",
    "\n",
    "The use of decorators is the most common way to use Numba. **Once called, the Numba decorated code / function is compiled JIT at native machine code speed.**\n",
    "\n",
    "For more details, visit the [documentation page](https://numba.pydata.org/numba-doc/latest/user/5minguide.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a9cc6-6cf2-4ad0-8023-7ccde92cdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def dot(a, b):\n",
    "    res = 0.\n",
    "    for i in range(len(a)): res += a[i] * b[i] #Inner most loop from the previous section.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94570f0f-7a7d-46f8-9a56-3f3b3e81bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a2312-81de-46be-ac68-d2553bf3116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dot(array([1., 2, 3]), array([2., 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40e2db-3db5-4932-841c-837052e5311b",
   "metadata": {},
   "source": [
    "By introducing these changes, we've brought CPU and Wall times down from 824 ms and 823 ms to 257 ms and 350 ms respectively. However, this is still pretty slow. The reason for this is that for the first run, Numba needs to compile our code on top of the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70dd21-dbcc-4d76-b9d6-14a66da66b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dot(array([1., 2, 3]), array([2., 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16f49e-1931-40ea-bede-4d4ee9d575fb",
   "metadata": {},
   "source": [
    "Let's alter the `matmul()` function to factor in the newly created `dot()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f6349-3954-4713-bddd-66096c51acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    (ar, ac), (br, bc) = a.shape, b.shape\n",
    "    # Create empty tensor\n",
    "    c = torch.zeros(ar, bc)\n",
    "    # Run updated loop\n",
    "    for i in range(ar):\n",
    "        for j in range(bc): c[i, j] = dot(a[i, :], b[:, j])\n",
    "    return c           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53e74d-ca8f-4ab7-a898-6e3021c50aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1a, m2a = m1.numpy(), m2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad66a0b-9c53-4652-8d58-bf6fbb71722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the FastAI library to test the performance improvements of this seemingly simple update.\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb7435-1729-4b25-bafd-2d0817b30bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, matmul(m1a, m2a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481c027-07ef-4a44-9ed9-c636ef1418c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43053235-13ab-4794-a126-7711a316c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 50 matmul(m1a, m2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2eafc-b372-4c36-ad47-542225871436",
   "metadata": {},
   "source": [
    "By adding `@njit` to the third part of the matrix multiplication loop, we've effectively sped up the operation by around **2000x**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e765021-11ca-4ae4-8286-045be41db549",
   "metadata": {},
   "source": [
    "## Element-Wise Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edacf121-1d27-4d94-9848-ed4ed106edee",
   "metadata": {},
   "source": [
    "This is a good place to introduce [APL (Array Programming Language)](https://tryapl.org/) which has\n",
    "\n",
    "> ...a powerful, concise syntax, it lets you develop shorter programs that enable you to think more about the problem you're trying to solve than how to express it to a .\n",
    "\n",
    "The code below, for element-wise operations was first tested in the APL interface and then applied in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f423596-5ab3-43b3-94c4-5ddf3c6b396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tensor([10., 6, -4])\n",
    "b = tensor([2., 8, 7])\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878fbff-9b3b-40f1-bb55-771fd2d21b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96fd09-f30b-4b64-b232-faf2a16ed6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a < b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da93de-70cb-4cb6-9e28-cabf647eefd5",
   "metadata": {},
   "source": [
    "An interesting fact that Jeremy shared was that there is no function for `mean` in APL. The language allows users to define such operations themselves and he used the following code to define the function:\n",
    "\n",
    "> **mean <- +/÷≢**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ccf3c4-20d7-45b6-b1bb-6f7ad294dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the mean of the binary results above, which we've already tested in APL\n",
    "(a < b).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f70dc8b-8e5e-4897-9935-d67f1bb6a95d",
   "metadata": {},
   "source": [
    "What is _even more interesting_ is the fact that we can carry out pretty much any kind of mathematical operation in APL. Just take the example of creating a 3x3 matrix below:\n",
    "\n",
    "> m ← 3 3 ⍴ ⍳9\n",
    "\n",
    "which is pretty awesome, considering that the output is the same as the PyTorch version below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfaf7e-45a3-463f-a0b7-6075fbaf048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tensor([[1., 2, 3], [4., 5, 6], [7., 8, 9]])\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226249c-ee2e-403f-9902-b9d8a6c61b10",
   "metadata": {},
   "source": [
    "Lets introduce the concept of Froebenius Norm, which is:\n",
    "\n",
    "> The Frobenius norm, sometimes also called the Euclidean norm (a term unfortunately also used for the vector L^2-norm), is matrix norm of an `m×n` matrix A defined as the square root of the sum of the absolute squares of its elements...The Frobenius Norm can also be considered as a vector norm and is expressed as:\n",
    "\n",
    "$$\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$$\n",
    "\n",
    "In code, this boils down to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab67c2-1ff5-4a9d-a7ee-c109214e405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = (m * m).sum()\n",
    "sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7987f33-ec46-4340-9000-243f6e87c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4031d-8b02-4ca5-952d-a5d8d4e2ef69",
   "metadata": {},
   "source": [
    "And to implement this in APL, we can take the matrix `m` which we created earlier, followed by:\n",
    "> sf <- +/,m*m\n",
    "> sf*0.5\n",
    "\n",
    "We need to multiply `sf` with 0.5 since APL doesn't have a square-root function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113b358-8322-45ff-a354-c93943d13ba8",
   "metadata": {},
   "source": [
    "With this additional knowledge, we can alter the `matmul()` even further by carrying out element-wise dot products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aab58a-8126-43f0-9835-e4f852f80b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    (ar, ac), (br, bc) = a.shape, b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc): c[i, j] = (a[i, :] * b[:, j]).sum()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9906ddb-3bc5-47a0-9b60-80d2860c6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41dc8c-6e78-4c63-b38c-b6b3bb7d1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 50 _ = matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62c082-5fb7-47cb-99ce-65f600c5743c",
   "metadata": {},
   "source": [
    "Which is slower than the Numba implementation, but orders of magnitude faster than the first version of `matmul()`. Lets see what using `torch.dot()` yeilds in terms of performance improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eafd606-5167-4525-83d0-57edceb557c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    (ar, ac), (br, bc) = a.shape, b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc): c[i, j] = torch.dot(a[i, :], b[:, j])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a3f5ee-f2cf-45b1-a59a-fc668d0b1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcec241-6c65-4740-866b-0d709ae271b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 50 _ = matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84a9e7-88f3-4095-9b88-6a1be25d515c",
   "metadata": {},
   "source": [
    "This is still slower than Numba!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9948352-88bd-4799-a54b-2ce6e76cd02f",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36127592-d93f-4b4b-85a7-9b66ffa1a4ee",
   "metadata": {},
   "source": [
    "### Broadcasting with a Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf211f0-32c3-4a66-9f08-d0fb24c60067",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cdaf3-dda5-489f-987e-fcb6a23f2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e845cd8-83b7-490f-afa8-ecefd9695a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is the same as \n",
    "a > tensor([0., 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8e6b3-f374-4ed5-9017-6e780a5f8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple operations\n",
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb894e2-672a-4229-a333-6b5c41d662c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0fe529-0b0b-4e0c-a5b5-4220000c4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da9460-b290-434b-86c2-518537fdc6b4",
   "metadata": {},
   "source": [
    "### Broadcast a Vector to a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362ba42-5a50-4676-b46d-75584444c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a rank 1 tensor\n",
    "c = tensor([10, 20, 30])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e917f65-94dc-443c-91fd-b55c12f96dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c4df1-2766-4c1d-bb57-d092bb6ecaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices can be added together\n",
    "m + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423008e4-16b7-46ae-ace1-78d8579d2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This also works both ways\n",
    "c + m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03708fdb-cedf-471c-92ad-ddadce25d915",
   "metadata": {},
   "source": [
    "These operations come from a slightly obscure concept called `expand_as()` which expands a tensor to the given size of another tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5c6c8-f436-4d3d-9942-d3f351a0dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our 1x3 tensor expands to a 3x3 shape\n",
    "t = c.expand_as(m)\n",
    "t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b3ea4-0f9d-47b0-a2eb-5b2ff5f693b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor.expand_as?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac6fc1-8e74-4ef5-8055-6d76f456c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check what resides in memory\n",
    "t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079aec9d-bdc3-4e6c-9db6-24b84b6b9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stride is the jump necessary to move to the next element\n",
    "t.stride(), t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a80e4-af17-449f-ae59-1b7434f4d36c",
   "metadata": {},
   "source": [
    "We can index with the special value `None`. Alternatively, `unsqueeze()` also converts a 1-dimensional array into a 2-dimensional array (with one of the dimensions having the value 1).\n",
    "\n",
    "Using `None` is more flexible than the `unsqueeze()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b2a6c-3acc-4078-9e16-cc1eb3479b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.unsqueeze(0), c[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673cf6a7-a678-4c6d-a588-983f2e62f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape, c.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e8061-ddf5-4f7a-9bf8-be55775d969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output one row with a new unit axis\n",
    "c.unsqueeze(1), c[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c82592-59f1-475d-8dda-5007108f2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triple dots will always insert a unit axis in a tensor, regardless of rank.\n",
    "c[None].shape, c[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015b0ca-2315-4d62-8958-1a2da57aea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to look at the expand_as() function.\n",
    "c[:, None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba5036-f215-4761-979e-2ae6e97a32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orientations of mathematical operations can be modified based on the above\n",
    "m + c[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c70664-4a69-4eb5-9351-7adf0006fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple flip changes the orientation of the sum.\n",
    "m + c[None, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63adb40-b1b7-4a80-9892-2056351d9c8f",
   "metadata": {},
   "source": [
    "### Broadcasting Rules\n",
    "\n",
    "Two dimensions are equal when:\n",
    "1. They are equal or,\n",
    "2. one of them is 1, which means the dimension is broadcasted to make it the same size.\n",
    "\n",
    "Also, arrays do not need to have the same number of dimensions for them to be able to interact with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1332f-4817-46f8-94ab-9b255f3cbce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[None, :], c[None, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b07b80-f01f-4f67-b3be-dd07679574b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[:, None], c[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c918446-7d16-476c-bffc-7c7fca0f0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This results in an outer product\n",
    "c[None, :] * c[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0e634-c683-4284-a768-a6bf56a32e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer boolean operations\n",
    "c[None, :] > c[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed75af46-3289-42b2-a967-67d36e1d76ee",
   "metadata": {},
   "source": [
    "## Matmul with Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a28c6d-6e00-42fa-b479-80da944a834f",
   "metadata": {},
   "source": [
    "We can now apply what we've learned about broadcasting to further speed up `matmul()`.\n",
    "\n",
    "So, now we can grab a single digit which is a 784x1 matrix. Using `expand_as()` on digit will give us the same shape as out weight matrix. We can then multiply both matrices to get a 784x10 result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3b23e-5fc6-481c-b0de-98fe8f516569",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = m1[0]\n",
    "digit.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c59fd7-d3a8-442b-976b-ac02d21095ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935aeb22-3a8d-408c-85bc-84e498b1c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit[:, None].expand_as(m2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b09aa-775c-4713-9bf0-a4495226ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(digit[:, None] * m2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed092594-d6f1-42f9-9207-cd5f35e9a0e6",
   "metadata": {},
   "source": [
    "Using this approach, we can add broadcasting to the `matmul()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d72af9-829f-4421-933d-68acc8d33bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    (ar, ac), (br, bc) = a.shape, b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        # Take the ith row, all the cols and add an axis at the end\n",
    "        # then multiply by b and sum it up\n",
    "        c[i] = (a[i, :, None] * b).sum(dim=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aae5ad-e896-4a8e-a6f0-2c3c9536985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1c75d-c644-4808-8eeb-e0a19a1a84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 50 _ = matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854e846-92d8-4140-8a22-4a6c5a96ef26",
   "metadata": {},
   "source": [
    "Let's test this out on the whole dataset, instead of just a mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dbccca-5394-4a0a-bdbc-1fd9b1c5c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = matmul(x_train, weights)\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cedcfb-9c10-4896-873e-c1d78ab95fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19e578-d80e-403a-85ef-0861200f0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = matmul(x_train, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccd701-cb5e-46bb-8bea-ba0b9432fb56",
   "metadata": {},
   "source": [
    "## Einstein Summation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c93dd81-c841-4eb4-a835-a4a368f67471",
   "metadata": {},
   "source": [
    "Compact representations of mathematical operations, like Einstein Summation, allow us to achieve considerable speed improvements over standard approaches. As this [blog](https://ajcr.net/Basic-guide-to-einsum/) states:\n",
    "\n",
    "> The einsum function is one of NumPy’s jewels. It can often outperform familiar array functions in terms of speed and memory efficiency, thanks to its expressive power and smart loops. On the downside, it can take a little while understand the notation and sometimes a few attempts to apply it correctly to a tricky problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5a630-0a9a-484d-9c5d-3b092a271589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going back to our m1 and m2 tensors\n",
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b16505-5c81-477b-999e-dd43c70c3961",
   "metadata": {},
   "source": [
    "In the notation below:\n",
    "- `i` is 5\n",
    "- `k` is 784\n",
    "- `j` is 10\n",
    "\n",
    "The resulting vector is 5x784x10, which is:\n",
    "- The original 5 rows of m1.\n",
    "- The original 10 columns of m2.\n",
    "- The 784 dimension is common to m1 and m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661bb70-3baa-40cf-a1d4-f56a2852323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Einsum notation in torch, and btw this also applies to Numpy\n",
    "mr = torch.einsum('ik,kj -> ikj', m1, m2)\n",
    "mr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a744e5-747d-4b3d-a6cb-cea4b2f6ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing up\n",
    "mr.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe83d88-6de8-4f61-a7f9-7c17b9ad0e9d",
   "metadata": {},
   "source": [
    "An interesting point to note is that omitting a letter from the output means that values along that axis will be summed. So, that allows us to further simplify the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b048c-a694-40d0-9d40-c76d08402abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case in point\n",
    "torch.einsum('ik,kj -> ij', m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912d0d2-055a-4cb4-b721-ae39a5afa397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewriting the matmul function\n",
    "def matmul(a,b):\n",
    "    return torch.einsum('ik,kj->ij', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f05ae98-a2a5-4867-99dd-4638018e0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running test close to check if the einsum result is equal to the original\n",
    "test_close(tr, matmul(x_train, weights), eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ddf600-a6a9-46f5-926f-311ec621a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 _ = matmul(x_train, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9861e2-37c8-443b-a4c9-d6b342fa0529",
   "metadata": {},
   "source": [
    "Which is considerably faster that even the broadcasting approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377d687-49bf-4685-bf3d-c4acbf863ef4",
   "metadata": {},
   "source": [
    "## PyTorch op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82ec43b-085d-4a70-92f1-9512c0b75a73",
   "metadata": {},
   "source": [
    "We can also use PyTorch's function / operator for matrix multiplication operations. The result, at least for this dataset is around the same as the Einsum implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf752c-fa61-4c20-bc3e-7ea4eaf76b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(tr, x_train@weights, eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77cbe7-f49c-454c-9364-1c278d5251fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 _ = torch.matmul(x_train, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0adcf5c-ce66-4e16-954a-465858fbbfd6",
   "metadata": {},
   "source": [
    "## CUDA - for warp speed!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb011973-8b5f-42e5-94f0-9ab601cdac55",
   "metadata": {},
   "source": [
    "The beauty of parallel processing, using CUDA, is that we can define self contained functions which won't interact with any other operations.\n",
    "\n",
    "We can build some intuition by rewriting the matmul() function to fill in only one number in a tensor. This effectively converts our matmul() into a kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69996ac7-09eb-45e1-a386-242aa1844020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version takes in an additional parameter called 'grid', which allows us to\n",
    "# set the location (using coordinates) of the single output.\n",
    "def matmul(grid, a, b, c):\n",
    "    # Grid inputs, should be inside the bounds of the output tensor\n",
    "    i, j = grid\n",
    "    if i < c.shape[0] and j < c.shape[1]:\n",
    "        # Start at 0\n",
    "        tmp = 0.\n",
    "        # Loop through all of the columns of a and the rows of b for i and j\n",
    "        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n",
    "        c[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c713b-2bd9-42dc-aea4-3fb345f88d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.zeros(ar, bc)\n",
    "# Run a matmul calculation and the output should be added to coordinates (0,0)\n",
    "matmul((0, 0), m1, m2, res)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0676514-bd09-49f9-8959-8190675295c7",
   "metadata": {},
   "source": [
    "Now, we need to launch the kernel and pass in the key parameters of the tensor grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d8d63-7edd-4d2c-a003-0bfbbda85962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_kernel(kernel, grid_x, grid_y, *args, **kwargs):\n",
    "    # Loop through the rows of a\n",
    "    for i in range(grid_x):\n",
    "        # Loop through the columns of b\n",
    "        for j in range(grid_y): kernel((i, j), *args, **kwargs) # Unpack as 3 separate args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18924b09-5702-42be-b763-02eba988cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.zeros(ar, bc)\n",
    "launch_kernel(matmul, ar, bc, m1, m2, res)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded9efb-420c-485f-a921-ee28a80caab6",
   "metadata": {},
   "source": [
    "Now that we have some intuition around this topic let's actually do it in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c26c90-8b91-4563-9926-575066b828d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d6d37-bbe1-4f66-b445-8855196b9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewriting the njit version of matmul() using cuda.\n",
    "# This implementation has just one small variation compared to the original.\n",
    "# The decorator compiles the following into GPU code.\n",
    "@cuda.jit \n",
    "def matmul(a, b, c):\n",
    "    # We call the grid here, specifying the number of dimensions \n",
    "    i, j = cuda.grid(2)\n",
    "    if i < c.shape[0] and j < c.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n",
    "        c[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b84225-f532-486e-a410-7493ddf9149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make sure that the local gpu is working properly\n",
    "# Peak wattage should be lower since we're using the standard ASUS profile.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6dae9-c7ea-4e78-aac5-28c25d448dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.zeros(tr.shape) # output tensor\n",
    "m1g, m2g, rg = map(cuda.to_device, (x_train, weights, r)) # 3 items to be copied to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c1853-eba7-4e43-b2e2-4b35ed1c21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb03c9b-3fef-4718-90a7-44100987c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 16 # Threads per block.\n",
    "rr, rc = r.shape\n",
    "blocks_per_grid = (math.ceil(rr / TPB), math.ceil(rc / TPB)) # Operations assigned to blocks\n",
    "blocks_per_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecc696-67a5-45ee-aaf5-d16d05beb648",
   "metadata": {},
   "source": [
    "For CUDA JIT to work, we need to add [] brackets in the next cell, which contains the `blocks_per_grid` result from the last cell and the TPB as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d7cfc-a9d9-4758-b409-4f5113cb3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul[blocks_per_grid, (TPB, TPB)](m1g, m2g, rg) # This launches the kernel\n",
    "r = rg.copy_to_host()\n",
    "test_close(tr, r, eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726354c2-724d-4746-800d-39d2998427a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "matmul[blocks_per_grid, (TPB, TPB)](m1g, m2g, rg)\n",
    "r = rg.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f47623-3001-4980-a6da-a6578ba4a896",
   "metadata": {},
   "source": [
    "Quite an improvement here. And different gaming profiles have a direct impact on the speed of calculations. For reference, I haven't enabled the \"Ultimate\" GPU mode.\n",
    "\n",
    "We can go even faster by using PyTorch ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651ed6c9-fde9-4b1e-a700-435f4a84e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying tensors over to the GPU\n",
    "m1c, m2c = x_train.cuda(), weights.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597930f-0512-4676-aabc-e8e3c6bb1009",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (m1c @ m2c).cpu() # copying operations to the host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5613f9-87ca-4a81-8586-374652512be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 r = (m1c @ m2c).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb553d9c-bb34-44eb-b942-d75244c07ed9",
   "metadata": {},
   "source": [
    "The final version is close to 5 million times faster than the original version."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
