{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41735e3-4044-4419-8e06-5a7b2260f2ff",
   "metadata": {},
   "source": [
    "# **Experiment with Training on a Pre-Trained Imagenet Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c481e-539d-4fad-bdf6-632aa4bd4ecd",
   "metadata": {},
   "source": [
    "One interesting exercise will be to apply Stable Diffusion using a pretrained model. Jeremy demostrated the application of ImageNet for this task. Recall that during the super resolution segment of the course, there was a huge difference in the performance of the pre-trained model compared to the newly trained model - with the prior clearly showing improved outputs compared to the latter. \n",
    "\n",
    "The same thinking can be applied here. However, we will need a pretrained latents model where the downsampling layers are pretrained on latents. A full ImageNet model, pretrained on latents should be up to the task.\n",
    "\n",
    "We can grab the full Imagenet model from Kaggle under the [ImageNet Object Localization Challenge](https://www.kaggle.com/c/imagenet-object-localization-challenge/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f65b8-9525-4db0-a585-82290ebc7908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "os.environ['OMP_NUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258ab65-2fc8-4149-b1cf-280d20c92920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip\n",
    "\n",
    "from glob import glob\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from fastprogress import progress_bar\n",
    "from diffusers import AutoencoderKL\n",
    "\n",
    "from miniai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cad869-267d-44c7-ba83-dfd9d7155669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53f63d-b435-4077-b37b-8fb45bb2354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=5, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['figure.dpi'] = 70\n",
    "\n",
    "set_seed(42)\n",
    "if fc.defaults.cpus>8: fc.defaults.cpus=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1324b4df-432a-472b-a76c-0895de33e0bb",
   "metadata": {},
   "source": [
    "We will download images from Kaggle to the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4609e69-b69e-4127-aa85-408f13adadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('data')/'ILSVRC'\n",
    "path = path_data/'Data'/'CLS-LOC'\n",
    "\n",
    "dest = path_data/'latents'\n",
    "dest.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d42fd3-b4b3-45ce-bcd7-75de238366ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-ema\").cuda().requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fadd8-39ea-4e52-b428-b243096ccd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDS:\n",
    "    def __init__(self, path, spec):\n",
    "        cache = path/'files.zpkl'\n",
    "        if cache.exists():\n",
    "            with gzip.open(cache) as f: self.files = pickle.load(f)\n",
    "        else:\n",
    "            self.files = glob(str(path/spec), recursive=True)\n",
    "            with gzip.open(cache, 'wb', compresslevel=1) as f: pickle.dump(self.files, f)\n",
    "\n",
    "    def __len__(self): return len(self.files)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        f = self.files[i]\n",
    "        im = read_image(f, mode=ImageReadMode.RGB) / 255\n",
    "        im = TF.resize(TF.center_crop(im, min(im.shape[1:])), 256)\n",
    "        return im, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed02bc-2a09-450f-b604-bac8f4bb01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageDS(path, '**/*.JPEG')\n",
    "dl = DataLoader(ds, batch_size=64, num_workers=fc.defaults.cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a4b21-0df3-464b-8d6e-b4b2b9fa69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(iter(dl))\n",
    "xe = vae.encode(xb.cuda())\n",
    "xs = xe.latent_dist.mean\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09da59-0b6c-490a-9ea6-bc5ef27a7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(((xs[:16,:3])/4).sigmoid(), imsize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ee57c-9fa3-47f8-9f76-3462495b98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = to_cpu(vae.decode(xs))\n",
    "show_images(xd['sample'][:16].clamp(0,1), imsize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574c167-9e01-48bb-bd20-f2a3610ee43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dest.exists():\n",
    "    dest.mkdir()\n",
    "    for xb, yb in progress_bar(dl):\n",
    "        eb = to_cpu(vae.encode(xb.cuda()).latent_dist.mean).numpy()\n",
    "        for ebi, ybi in zip(eb, yb):\n",
    "            ybi = dest/Path(ybi).relative_to(path).with_suffix('')\n",
    "            (ybi.parent).mkdir(parents=True, exist_ok=True)\n",
    "            np.save(ybi, ebi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ab2f2-90e1-4aed-b479-00eff3cdae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDS(ImageDS):\n",
    "    def __getitem__(self, i):\n",
    "        f = self.files[i]\n",
    "        im = np.load(f)\n",
    "        return im, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599c562-ebb1-4325-8294-1976a0c76baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a599121-c39a-4f7c-a5e4-3e6c22a7192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = NumpyDS(dest/'train', '**/*.npy')\n",
    "vds = NumpyDS(dest/'val', '**/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e54f7-850b-4958-8c15-5f7ef3c416a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdl = DataLoader(tds, batch_size=bs, num_workers=0)\n",
    "xb,yb = next(iter(tdl))\n",
    "\n",
    "xb.mean((0,2,3)), xb.std((0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99171fea-da52-40b0-a77f-6fddf0b8f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmean, xstd = (tensor([5.37007, 2.65468, 0.44876, -2.39154]),\n",
    "               tensor([3.99512, 4.44317, 3.21629, 3.10339]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e4ef1-de2d-4eb0-b5da-d0f84d525e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfmDS:\n",
    "    def __init__(self, ds, tfmx=fc.noop, tfmy=fc.noop): self.ds, self.tfmx, self.tfmy = ds, tfmx, tfmy\n",
    "\n",
    "    def __len__(self): return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.ds[i]\n",
    "        return self.tfmx(x), self.tfmy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5043e-b27c-4613-b38d-ca329e6143d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2str = (path_data/'imagenet_lsvrc_2015_synsets.txt').read_text().splitlines()\n",
    "str2id = {v:k for k,v in enumerate(id2str)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a0529-d997-48a3-b591-1490aadeca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms = nn.Sequential(T.Pad(2), T.RandomCrop(32), RandErase())\n",
    "norm_tfm = T.Normalize(xmean, xstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517fb290-d5b2-4e12-b7c7-6dff1ad98a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfmx(x, aug=False):\n",
    "    x = norm_tfm(tensor(x))\n",
    "    if aug: x = aug_tfms(x[None])[0]\n",
    "    return x\n",
    "\n",
    "def tfmy(y): return tensor(str2id[Path(y).parent.name])\n",
    "\n",
    "tfm_tds = TfmDS(tds, partial(tfmx, aug=True), tfmy)\n",
    "tfm_vds = TfmDS(vds, tfmx, tfmy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563b10c-fd3e-4bcb-8500-d0d82c47cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x): return (x*xstd[:,None,None]+xmean[:,None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d45f6-d431-4602-9815-5cbf182e0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(*get_dls(tfm_tds, tfm_vds, bs=bs, num_workers=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a1060-6c16-4691-9486-7033cc4bcf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synsets = [o.split('\\t') for o in (path_data/'words.txt').read_text().splitlines()]\n",
    "synsets = {k:v.split(',', maxsplit=1)[0] for k,v in all_synsets if k in id2str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba11c18-8301-4b91-b8a4-14593c024f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(iter(dls.train))\n",
    "titles = [synsets[id2str[o]] for o in yb]\n",
    "xb.mean(),xb.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b2b87-dcb5-473d-9eb0-92c5f6e7d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = to_cpu(vae.decode(denorm(xb[:9]).cuda()))\n",
    "show_images(xd['sample'].clamp(0, 1), imsize=4, titles=titles[:9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
