{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8578e7c9-e365-41ae-84d5-9309d45e603f",
   "metadata": {},
   "source": [
    "## **The Forward and Backward Passes of a Simple MLP / Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adb44585-199f-4443-a686-f9f8a3ffda74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip, math, os, time, shutil\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "from torch import tensor\n",
    "from fastcore.test import  test_close\n",
    "from pathlib import Path\n",
    "\n",
    "# Configs\n",
    "torch.manual_seed(42)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=125)\n",
    "\n",
    "# Path setup\n",
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "# Loading MNIST data as tensors\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048eeac-ec99-4e49-a81e-dbd7dea1f229",
   "metadata": {},
   "source": [
    "## Building the Foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64614a9e-b6fe-4282-a614-fc9e342f7705",
   "metadata": {},
   "source": [
    "### Basic Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9729c1f-fa12-4727-b34d-7c2e0e8e0074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here n is the number of training examples and m is the number of pixels\n",
    "n, m = x_train.shape\n",
    "# C is the number of possible values of our outputs / digits\n",
    "c = y_train.max() + 1\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a018961b-f0c4-4c26-8588-1a293db2e9c5",
   "metadata": {},
   "source": [
    "We will decide ahead of time what the number of our hidden **activations** or **nodes** for a single layer will be. Lets pick an arbitrary number..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dda0f8f4-f9e6-42cb-9d50-ce24ae00c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hidden activations\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e302f-1441-4009-8831-2f3e30ab856e",
   "metadata": {},
   "source": [
    "As we have already established, we will be utilizing what we've learnt about matrix multiplications to get our output probabilities for each input row. We already have training data in a **`50,000x784`** matrix. For the linear function to work, we will need weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83bb6a51-0f57-43bc-b966-3b1866324209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The weight matrix will contain 50000x50 random values\n",
    "w1 = torch.randn(m ,nh)\n",
    "# Adding the biases for summation operations to create the linear function.\n",
    "# Creating a matrix of 0s, one for each hidden activation\n",
    "b1 = torch.zeros(nh)\n",
    "# For layer two, we will start with nh inputs.\n",
    "# But, we will stick with 1 output column to simplify the loss calcs. Which will be MSE instead of cross entropy.\n",
    "w2 = torch.randn(nh, 1)\n",
    "#  The sample applies for the bias i.e. sticking with a single output for simplicity.\n",
    "b2 = torch.zeros(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f59504e-6f58-42e3-aecc-df4dcecd35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple linear function for putting X through a single layer\n",
    "def lin(x, w, b): return x@w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8d057b0-8716-484f-b310-08b24ff83565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying the shape of our validation matrix\n",
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd5d5371-63e8-4d2a-a450-e07ecc8ef608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 50])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing the validation data through the linear function with result in a 10000x50 matrix\n",
    "t = lin(x_valid, w1, b1)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94e20bff-35f3-4e29-8809-39382041cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing the results through a ReLU\n",
    "def relu(x): return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7979256d-7b3b-4a7c-862a-b7c628248286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.00,  0.00,  0.00,  ...,  4.04,  0.00,  0.00],\n",
       "        [ 3.56,  0.00,  0.00,  ...,  0.88,  3.10,  0.00],\n",
       "        [ 6.66,  4.48,  0.00,  ...,  5.81,  8.84,  3.07],\n",
       "        ...,\n",
       "        [16.45,  0.00,  0.00,  ..., 11.17,  0.00,  0.00],\n",
       "        [ 7.03,  0.51,  0.00,  ...,  8.39,  0.00,  3.69],\n",
       "        [10.94,  0.00,  0.00,  ...,  0.00,  0.00, 11.96]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45780640-b7ba-43b4-a050-9e9d651060d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A basic MLP which takes a mini-batch of data\n",
    "def model(xb):\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    return lin(l2, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc69a2fe-5fc9-425a-a013-162d441ed178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model will now output a single column output\n",
    "# Again, this is only for simplicity since we will be testing the model using MSE.\n",
    "res = model(x_valid)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27bb9d-6c92-49de-883d-7cc56f3a703a",
   "metadata": {},
   "source": [
    "### Simple Loss Function: Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6184157-4991-4dde-8caa-c117f481c105",
   "metadata": {},
   "source": [
    "MSE is not a suitable loss function for multi-class classification. The simplicity here is for demonstration purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb59cb20-4a23-4bcf-98d6-97cb9a083696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 1]), torch.Size([10000]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e17822e7-5929-4eea-8cbf-5cdf77d77f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res - y_valid).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d483a-5cfd-4a9a-be32-db5b7d7af478",
   "metadata": {},
   "source": [
    "The calculation above is not correct. At the moment, based on broadcasting rules, each of our 10000 row items will be subtracted by the 10000 items in the array. PyTorch will automatically insert a unit x-axis in `y_valid`. This is not the shape of outputs that we desire!\n",
    "\n",
    "For correct element-wise operations, we will get rid of the trailing unit axis in `res`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7600f12c-a85e-4e36-9aec-cfbb55f3da4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One option is to use indexing to remove the trailing dimension\n",
    "res[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee04a63f-e572-4809-90d1-0cf676d7566f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we can use squeeze() to drop all trailing unit dimensions\n",
    "res.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc6e54f8-3a05-4d06-ac7b-448d48a287b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10000, 1, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo: Adding arbitrary unit dimensions\n",
    "test = res[None, :, None, None]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "210b8465-4f80-411b-9a62-6f640471d7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using squeeze()\n",
    "test.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae533178-805f-4e9a-816d-c34f721a19de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our results will now have the correct shape\n",
    "(res.squeeze() - y_valid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "731488af-cec0-4674-98f8-33f9c6322077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets calculate our predictions for the training set\n",
    "# Converting to float for MSE\n",
    "y_train, y_valid = y_train.float(), y_valid.float()\n",
    "\n",
    "preds = model(x_train)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "430497b2-f3bd-4dbb-a0d9-06e26c35ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an MSE function\n",
    "# Alternatively, we can also use out[:, 0] instead of squeeze as we have already established\n",
    "def mse(output, target): return (output.squeeze() - target).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7780ae8d-bd7c-4194-9b5e-d9f9b0d6be2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1549.37)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750ffd6-ed08-426c-96ff-e15336fa6149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27367fc0-e8eb-4840-b153-53e12d27a8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb5d62-064f-41a2-84b2-80ea72d68f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38094162-7273-4e1c-b960-1fa87fa9c700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a861b6-cddf-41ae-8fe5-3c45d977145e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e2739-a044-4c52-8ae4-39969b9c5323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea9e68-8922-4330-8ef5-1529b6a0c18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a42e2-10dc-4570-8dfb-9e6db93b9d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562985ba-e55c-4252-84c4-10662f1ad940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abc224-6a90-47f7-b3c6-c667ec42732f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321d54c-4f7b-452c-b9c6-dde1ed7f121f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7f2ae-60e8-4f17-ae79-0cd6f4534a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f412fa-0992-4eb3-b30f-f55c21124276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2342bd-3b86-465a-aa93-6a12a1a424ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
