{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f39363-6601-41c6-8e11-5f214ce26c41",
   "metadata": {},
   "source": [
    "# **Setting Up A Diffusion UNet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2744b50-e0bc-45c8-b701-908f8eaf73c7",
   "metadata": {},
   "source": [
    "In this NB, we will train an unconditional diffusion model from scratch which will mostly be built using the pipeline components we've already built for this course - in addition to the model specific components from the **Karras Implementation NB i.e. 21_karras_implementation**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3625af93-a79c-4d6f-a622-65a23580d131",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733fe828-c21c-475f-8331-b85d0e6324bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timm, torch, random, datasets, math, fastcore.all as fc\n",
    "import numpy as np, matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import k_diffusion as K, torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF, torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from pathlib import Path\n",
    "from torch.nn import init\n",
    "from fastcore.foundation import L\n",
    "from torch import nn, tensor\n",
    "from datasets import load_dataset\n",
    "from operator import itemgetter\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from functools import partial\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import optim\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.conv import *\n",
    "from miniai.learner import *\n",
    "from miniai.activations import *\n",
    "from miniai.init import *\n",
    "from miniai.sgd import *\n",
    "from miniai.resnet import *\n",
    "from miniai.augment import *\n",
    "from miniai.accel import *\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n",
    "if fc.defaults.cpus>8 : fc.defaults.cpus=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56369d6-aa68-4812-addb-92895f9a2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress import progress_bar\n",
    "from diffusers import UNet2DModel, DDIMPipeline, DDPMPipeline, DDIMScheduler, DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90098a47-1cc4-491c-bf4a-a91aabf48d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=5, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray_r'\n",
    "mpl.rcParams['figure.dpi'] = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358b28fc-3344-4b0c-af41-8adf68d8b22c",
   "metadata": {},
   "source": [
    "## **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ddd713d-4fa3-42a8-b18f-19bdbf32431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a33b0f3fccf4437818d4d4acc286bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb25bd6d89541cc9d31d7a7335bfc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/30.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56ae33dde364144a9e224b829cc607d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/5.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a14eaee6c0c472eb9a1b73ccb809817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0a478b390a491b81ac3f479e83f035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xl, yl = 'image', 'label'\n",
    "name = \"fashion_mnist\"\n",
    "n_steps = 1000\n",
    "bs = 512\n",
    "dsd = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339b3828-05e2-402f-a72d-3346ab7f7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the standard deviation of the input data as sigma. Bear in mind that the inplace tfms\n",
    "# will have an impact on this value.\n",
    "sig_data = 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa6375c-e684-4012-b020-3b70d234574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b): b[xl] = [F.pad(TF.to_tensor(o), (2, 2, 2, 2))*2-1 for o in b[xl]]\n",
    "\n",
    "def scalings(sig):\n",
    "    # Total variance at a particular level of sigma\n",
    "    totvar = sig**2 + sig_data**2\n",
    "           #c_skip           , # c_out                   , #c_in\n",
    "    return sig_data**2/totvar, sig*sig_data/totvar.sqrt(), 1/totvar.sqrt()\n",
    "\n",
    "def noisify(x0):\n",
    "    device = x0.device\n",
    "    # Log normal distribution of sigmas\n",
    "    sig = (torch.randn([len(x0)])*1.2-1.2).exp().to(x0).reshape(-1, 1, 1, 1)\n",
    "    noise = torch.randn_like(x0, device=device)\n",
    "    # Calculate values to pick an input between a clean image and pure noise\n",
    "    c_skip, c_out, c_in = scalings(sig)\n",
    "    noised_input = x0 + noise*sig\n",
    "    # The target is based on a mixture of both noise and clean images with scaling\n",
    "    # being done by c_out\n",
    "    target = (x0 - c_skip*noised_input) / c_out\n",
    "    # Noised input is scaled up or down using c_in\n",
    "    return (noised_input*c_in, sig.squeeze()), target\n",
    "\n",
    "def collate_ddpm(b): return noisify(default_collate(b)[xl])\n",
    "def dl_ddpm(ds)    : return DataLoader(ds, batch_size=bs, collate_fn=collate_ddpm, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97e0ee17-f414-4832-ae2e-0d037670522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders(dl_ddpm(tds['train']), dl_ddpm(tds['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d244907-184f-42a6-a1c6-ffd6b585fd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (60000, 2), 'test': (10000, 2)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409f0d7-5a37-4f9f-8295-6d1d3c85b53a",
   "metadata": {},
   "source": [
    "## **Train Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae42937-14ed-4a0c-905a-5692fd0bee0f",
   "metadata": {},
   "source": [
    "The unconditional model will be trained using the UNet architecture from previous NBs and the **Diffusers** library.\n",
    "\n",
    "Additionally, we will be using the [SiLU](https://mlarchive.com/machine-learning/activation-functions-all-you-need-to-know/) or the Sigmoid Activation Function.\n",
    "\n",
    "![title](imgs/SiLU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44938d6-c8c4-493b-abba-3f18423f778e",
   "metadata": {},
   "source": [
    "Using the same convolution as the one from Tiny Imagenet, which is also called the **pre-activation convolution**. \n",
    "\n",
    "Preactivation convolution refers to a specific architectural design in NNs where the batch normalization and activation functions are applied before the convolution operation. This approach is primarily associated with enhancing the performance of deep learning models, particularly in residual networks (ResNets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "966e5564-dc54-40ef-b51b-e186943bbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv(ni, nf, ks=3, stride=1, act=nn.SiLU, norm=None, bias=True):\n",
    "    layers = nn.Sequential()\n",
    "    if norm: layers.append(norm(ni))\n",
    "    if act : layers.append(act())\n",
    "    layers.append(nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2, bias=bias))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51d20a7-eed2-4d90-9999-61c72714b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The structure is same as previous ResNet blocks with the exception that there is no option\n",
    "# for down sampling and strides. That will be featured in the down_block(). This approach is similar\n",
    "# to the one used in Diffusers.\n",
    "class UnetResBlock(nn.Module):\n",
    "    def __init__(self, ni, nf=None, ks=3, act=nn.SiLU, norm=nn.BatchNorm2d):\n",
    "        super().__init__()\n",
    "        if nf is None: nf = ni\n",
    "        self.convs = nn.Sequential(unet_conv(ni, nf, ks, act=act, norm=norm),\n",
    "                                   unet_conv(nf, nf, ks, act=act, norm=norm))\n",
    "        self.idconv = fc.noop if ni==nf else nn.Conv2d(ni, nf, 1)\n",
    "\n",
    "    def forward(self, x): return self.convs(x) + self.idconv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea2acc-dee4-48a2-ab29-f95ef03267f7",
   "metadata": {},
   "source": [
    "By not adding _stride_ and _down-sampling_ to `UnetResBlock()`, we are ensuring that our approach is similar to the one used in the original `DDPM` architecture.\n",
    "\n",
    "We will try to simplify how different down-sampling blocks can be incorporated into UNets. One way to do this is to introduce the `SavedResBlock()` and `SavedConv()` modules. These two components have similar functionality as ResBlock() and Conv(), but are also able to store the activations. This makes the activations accessible as we develop the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c8137ff-3e4a-4e03-b3a5-a4362ea5531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModule:\n",
    "    # Calls forward to grab the ResBlock and Conv results and stores them.\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        # Using Mixin which contains methods for use by other classes (multiple inheritance)\n",
    "        # without having to be the parent class of those other classes.\n",
    "        self.saved = super().forward(x, *args, **kwargs) \n",
    "        return self.saved\n",
    "\n",
    "# These classes only carry out Mixin ops for the target classes.\n",
    "class SavedResBlock(SaveModule, UnetResBlock): pass # multiple inheritance, First call is used with the second argument \n",
    "class SavedConv(SaveModule, nn.Conv2d): pass        # same as above. This allows UnetResBlock and Conv2d outputs to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a306d4f8-9f94-45d3-9e37-9e394ca55176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(ni, nf, add_down=True, num_layers=1):\n",
    "    # SaveModule ops used Sequentially.\n",
    "    res = nn.Sequential(*[SavedResBlock(ni=ni if i==0 else nf, nf=nf)\n",
    "                         for i in range(num_layers)])\n",
    "    # Carry out down sampling if needed.\n",
    "    if add_down: res.append(SavedConv(nf, nf, 3, stride=2, padding=1))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97f8fa75-3ace-4513-a49a-2fdbe97cfa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling will be done with a sequence of upsampling layers - followed by a simple 3x3 conv.\n",
    "# Again this approach is the one preferred by the Stable Diffusion team.\n",
    "def upsample(nf): return nn.Sequential(nn.Upsample(scale_factor=2.), nn.Conv2d(nf, nf, 3, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22060054-e096-4f4f-bc3f-21f43d2e545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    # Storing previous number of filters.\n",
    "    def __init__(self, ni, prev_nf, nf, add_up=True, num_layers=2):\n",
    "        super().__init__()\n",
    "        # Using the saved results in the upsampling path\n",
    "        self.resnets = nn.ModuleList(\n",
    "            [UnetResBlock((prev_nf if i==0 else nf) + (ni if (i==num_layers-1) else nf), nf)\n",
    "             for i in range(num_layers)])\n",
    "        # Add an upsampling layer if asked.\n",
    "        self.up = upsample(nf) if add_up else nn.Identity()\n",
    "\n",
    "    def forward(self, x, ups):\n",
    "        # Call each resnet as we progress in the upsampling path. Concatenate downsampling activations with each upsampling\n",
    "        # layer at the end.\n",
    "        for resnet in self.resnets: x = resnet(torch.cat([x, ups.pop()], dim=1)) # Concatenate\n",
    "        return self.up(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b78c7-221c-4f22-8f5d-70ddac5268e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ab45b-6326-4a9d-aa3b-0c4a1f4863a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50cf3ae-fe0e-4573-bf95-cc1c57a78b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8bd51a-8371-4f62-8ecc-b8fff43c537b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752b31c-e2dd-4422-9f2d-4af8c34d6a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb024f04-c3dd-4fb3-a8e7-9003292fcfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516caf08-8052-4542-b2f7-4e357e651a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e69315-1c1a-44b5-b581-899d0ed47d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbf4ea-39a6-4563-a417-8a66a71b2e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2cbc6-1a48-4bcc-9e05-e2badb61a294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93318c8-c13c-435f-bf1a-9ed6c90fd612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0b5b5-6aea-461e-b428-8120e0966e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6fa36-7307-4ff6-8d3e-77f460806517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98c5854-bd06-4013-97dc-c8691cccf99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef8ee8-d2ef-4936-b76b-eb6671862ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec6b0e2-9ae7-4ed5-bd11-1b8845a543e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408b745-5257-4b89-bbff-17c61f83e7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d632cf-2b5a-4c51-8606-a8b4c7fe56f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d481a8-afab-44fe-bdd5-bc885905f425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8fb03-ace3-4f8f-9d2f-bc1c38b7d3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
