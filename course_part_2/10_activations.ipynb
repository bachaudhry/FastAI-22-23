{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eddad46-5c14-4560-ab47-cda2617eee56",
   "metadata": {},
   "source": [
    "# **Monitoring Activation Stats**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e87c05-bfa3-46c9-b86f-fd49bac451a6",
   "metadata": {},
   "source": [
    "This NB will focus on building functionality to allow the monitoring of activation stats during the modelling process. Thus allowing us to diagnose issues during both training and inference, by actually looking _inside_ the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94717921-75ab-4313-b3b6-02c46a546d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import random,math,torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from functools import partial\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154e42e5-5e50-40ab-a209-89dc0c566aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path\n",
    "from operator import attrgetter,itemgetter\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from torch import tensor,nn,optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from datasets import load_dataset\n",
    "\n",
    "from fastcore.test import test_close\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "mpl.rcParams['figure.constrained_layout.use'] = True\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3373016-682d-4858-a860-d8c9c9a2d751",
   "metadata": {},
   "source": [
    "To enable reproducibility, especially for the context of modelling on a single machine, we will use PyTorch's `use_deterministic_algorithms` flag.\n",
    "\n",
    "According to [PyTorch](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html#torch-use-deterministic-algorithms):\n",
    "\n",
    "> ...algorithms which, given the same input, and when run on the same software and hardware, always produce the same output. When enabled, operations will use deterministic algorithms when available, and if only nondeterministic algorithms are available they will throw a `RuntimeError` when called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a1db40-cbab-47a8-86fc-6651bc1b6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed, deterministic=False):\n",
    "    torch.use_deterministic_algorithms(deterministic)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47eba95-25a8-4c90-ae2b-c585a1a04dde",
   "metadata": {},
   "source": [
    "## **Get Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3f59a-fba1-4ac9-adcb-6eff20942322",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = 'image','label'\n",
    "name = \"fashion_mnist\"\n",
    "dsd = load_dataset(name)\n",
    "bs = 1024\n",
    "\n",
    "@inplace\n",
    "def transformi(b): b[x] = [TF.to_tensor(o) for o in b[x]]\n",
    "\n",
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(tds, bs, num_workers=4)\n",
    "dt = dls.train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a2f00-0dc9-4c84-881f-e6bacb381a5d",
   "metadata": {},
   "source": [
    "## **Create a Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d88c27-9cf9-427b-b6d4-850f698f204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni, nf, ks=3, act=True):\n",
    "    res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)\n",
    "    if act: res = nn.Sequential(res, nn.ReLU())\n",
    "    return res\n",
    "\n",
    "def cnn_layers():\n",
    "    return [\n",
    "        conv(1 ,8, ks=5),        #14x14\n",
    "        conv(8 ,16),             #7x7\n",
    "        conv(16,32),             #4x4\n",
    "        conv(32,64),             #2x2\n",
    "        conv(64,10, act=False),  #1x1\n",
    "        nn.Flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed051752-9bf3-42a4-86d6-65842911b65b",
   "metadata": {},
   "source": [
    "We'll be training at a higher learning rate not only to save time, but also to find a more generalizable set of weights. Jeremy also says that training at a higher learning rate ensures \"stable training\". **This is something I need to dig into**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079e9f4-be1d-4d97-b66b-2028a4fd4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106950a-fab3-42d4-b772-3dd239c6d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())\n",
    "cbs = [TrainCB(), DeviceCB(), metrics, ProgressCB(plot=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b09e51-d7db-4901-9f88-d390f01bea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epochs=1, xtra_cbs=None):\n",
    "    learn = Learner(model, dls, loss_func=F.cross_entropy, lr=0.6, cbs=cbs+fc.L(xtra_cbs))\n",
    "    learn.fit(epochs)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9ae00-f9fd-4be6-b062-109990ca7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "learn = fit(nn.Sequential(*cnn_layers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089cf53d-3061-42fb-9bcb-3191add10dc1",
   "metadata": {},
   "source": [
    "Clearly the model's training process isn't off to a good start. This means there has to be something wrong with our initial activations. Time to build some functionality which allows us to look into the different layers of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34227f4-71cb-44ac-8186-d89fef1f9b19",
   "metadata": {},
   "source": [
    "## **Using Hooks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcefa29-e408-402d-8f51-acff068e8dec",
   "metadata": {},
   "source": [
    "### **Manual Insertion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24b31e-557c-44db-a3ba-ab658b79cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, *layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers) # covered in earlier nbs\n",
    "        # Taking the means and std of the activations\n",
    "        self.act_means = [[] for _ in layers]\n",
    "        self.act_stds = [[] for _ in layers]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for i, l in enumerate(self.layers):\n",
    "            x = l(x)\n",
    "            self.act_means[i].append(to_cpu(x).mean())\n",
    "            self.act_stds[i].append(to_cpu(x).std())\n",
    "        return x\n",
    "\n",
    "    def __iter__(self): return iter(self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced00672-a2a1-4bea-8ca1-487263e13169",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "model = SequentialModel(*cnn_layers())\n",
    "learn = fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87e6d8-a7db-4551-b8c0-c31b4b59efbf",
   "metadata": {},
   "source": [
    "Now we can plot the activation means, for each batch, broken out by individual layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec287b-e3b4-4048-8520-be88bc507776",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.act_means: plt.plot(l)\n",
    "plt.legend(range(5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8ffce-1fca-46b9-bfe3-e88705037eb3",
   "metadata": {},
   "source": [
    "The same for standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165629cd-1fd3-4906-8552-8a21af53a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.act_stds: plt.plot(l)\n",
    "plt.legend(range(5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098335be-acba-4285-9b5b-12b315c96aa1",
   "metadata": {},
   "source": [
    "If activations don't follow the general rule of having their means close to 0 and standard deviations close to one - that usually indicates that we have dead neurons with failed activations.\n",
    "\n",
    "So, our model has failed before it even began to train for increased epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8afc38b-e77e-49f0-b02f-a48be5475acb",
   "metadata": {},
   "source": [
    "### **PyTorch Hooks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8793711b-a536-4a60-b0bb-9b727e80e0cf",
   "metadata": {},
   "source": [
    "> Hooks are PyTorch object you can add to any nn.Module. A hook will be called when a layer, it is registered to, is executed during the forward pass (forward hook) or the backward pass (backward hook). Hooks don't require us to rewrite the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9b1f7-68d3-40af-87e3-aa877024cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "model = nn.Sequential(*cnn_layers())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16d46f-ee03-4f6e-8084-925a3d23cbb1",
   "metadata": {},
   "source": [
    "We will still need to track the activations means and standard deviations. Since the hook is attached to a layer and takes three arguments, i.e. module, input, output, we will need to store the mean and std of the _output_ in the correct position of our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517fd1a-8b79-4bd1-bd22-c89613bc9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_means = [[] for _ in model]\n",
    "act_stds = [[] for _ in model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e67ca-fc7b-454b-b71b-1a497cec2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_stats(i, mod, inp, outp): # Function called by the hook, where i is the layer number\n",
    "    act_means[i].append(to_cpu(outp).mean())\n",
    "    act_stds [i].append(to_cpu(outp).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b054fb5e-944b-4a1c-bcb3-7c824aa3a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in enumerate(model): m.register_forward_hook(partial(append_stats, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392c093-e845-4a60-8a92-f59ce409ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe21bb-de79-4096-9069-ec43a8fca5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in act_means: plt.plot(o)\n",
    "plt.legend(range(5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84730103-ada5-46a8-a184-1c5521cce61b",
   "metadata": {},
   "source": [
    "### **Refactored Hook Class**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f9b3b-da4d-4cc3-a421-158a89fd1cd1",
   "metadata": {},
   "source": [
    "> It's very important to remove the hooks when they are deleted, otherwise there will be references kept and the memory won't be properly released when your model is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1c2e1-7c92-4f57-97f0-9bf07ad4c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook(): # Ensuring that hooks and their references are deleted \n",
    "    def __init__(self, m, f): self.hook = m.register_forward_hook(partial(f, self)) # Forward pass only\n",
    "\n",
    "    def remove(self): self.hook.remove() #Free hook object\n",
    "\n",
    "    def __del__(self): self.remove() #Delete hook object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9e0fa-96c3-4186-9738-d1a5e10a400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_stats(hook, mod, inp, outp):\n",
    "    if not hasattr(hook,'stats'): hook.stats = ([],[]) # create stats if they don't exist.\n",
    "    acts = to_cpu(outp)\n",
    "    hook.stats[0].append(acts.mean())\n",
    "    hook.stats[1].append(acts.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562c54f-8028-43b9-be53-ed94c631dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "model = nn.Sequential(*cnn_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04d4d2-b2e3-4156-ab68-7900a7dc1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = [Hook(l, append_stats) for l in model[:5].children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4700a3-8bad-4109-bde4-bbe8f049e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef4fc6-7494-4e87-8064-d4dc4c4cc579",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in hooks:\n",
    "    plt.plot(h.stats[0])\n",
    "    h.remove()\n",
    "plt.legend(range(5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a5e39-9009-4ce0-bc9b-2c7fb4ed747e",
   "metadata": {},
   "source": [
    "### **A Convenient Hooks Class**\n",
    "#### **Demo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a7b1df-b56a-4953-86d6-4498c1e4a612",
   "metadata": {},
   "source": [
    "We can create our own context managers and also modify how base Python works!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffdd936-bdb7-44b1-903c-e21c5253f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for demo purposes\n",
    "class DummyCtxMgr():\n",
    "    def __enter__(self, *args):\n",
    "        print(\"Starting Up!\")\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args): print(\"Wrapping up!\")\n",
    "\n",
    "    def hello(self): print(\"Ola!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e19b27-becb-4604-8fda-ed62b209609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DummyCtxMgr() as dcm: dcm.hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3a7d7-abb4-4ea2-9a90-28b9146fd06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still for demos\n",
    "class DummyList(list):\n",
    "    def __delitem__(self, i): # Redefine how __delitem__() works \n",
    "        print(f\"Dropping item {i}\") # Call list\n",
    "        super().__delitem__(i) # Drop and return updated list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870c0df-00c4-43e3-b38d-d771f44ca647",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml = DummyList([1, 3, 2])\n",
    "dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89820af-7845-42ba-99d4-1bceb297ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete item by index\n",
    "del(dml[1])\n",
    "dml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637942b-5350-4a14-b5bf-bba327485bb4",
   "metadata": {},
   "source": [
    "#### **Custom Hooks Class**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8bc75-3e4e-48bb-afa2-c424dc6d30cf",
   "metadata": {},
   "source": [
    "We can create a handy context manager to handle operations linked to Hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0721a7-658e-4205-ae23-d5fd8b1b87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hooks(list):\n",
    "    def __init__(self, ms, f): super().__init__([Hook(m, f) for m in ms]) # Inherits from the list\n",
    "\n",
    "    def __enter__(self, *args): return self # Called when \"with\" statement is used, returns just the object itself\n",
    "\n",
    "    def __exit__(self, *args): self.remove() # Called at the end of the block\n",
    "\n",
    "    def __del__(self): self.remove()\n",
    "\n",
    "    def __delitem__(self, i): # Can delete single hook from the list\n",
    "        self[i].remove()\n",
    "        super().__delitem__(i)\n",
    "\n",
    "    def remove(self):\n",
    "        for h in self: h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450b576-343d-4216-862e-998640eb595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "model = nn.Sequential(*cnn_layers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e77d6-c796-4b28-9073-7e27974de8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hooks() will act as a context manager\n",
    "with Hooks(model, append_stats) as hooks:\n",
    "    fit(model)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for h in hooks:\n",
    "        for i in 0, 1: axs[i].plot(h.stats[i])\n",
    "    plt.legend(range(6));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e95bb1-5ca4-43c8-a752-a444a7bb2ad4",
   "metadata": {},
   "source": [
    "### **HooksCallback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c3bab-0e6e-4c1f-8434-32d4605b300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HooksCallback(Callback):\n",
    "    def __init__(self, hookfunc, mod_filter=fc.noop, on_train=True, on_valid=False, mods=None):\n",
    "        fc.store_attr()\n",
    "        super().__init__()\n",
    "\n",
    "    def before_fit(self, learn):\n",
    "        if self.mods: mods = self.mods\n",
    "        else: mods = fc.filter_ex(learn.model.modules(), self.mod_filter)\n",
    "        self.hooks = Hooks(mods, partial(self._hookfunc, learn))\n",
    "\n",
    "    def _hookfunc(self, learn, *args, **kwargs):\n",
    "        if (self.on_train and learn.training) or (self.on_valid and not learn.training): self.hookfunc(*args, **kwargs)\n",
    "\n",
    "    def after_fit(self, learn): self.hooks.remove()\n",
    "\n",
    "    def __iter__(self): return iter(self.hooks)\n",
    "\n",
    "    def __len__(self): return len(self.hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d538ae6-da8d-4f53-93bb-5f889cb017f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "?fc.noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6a788-9486-40a9-92ef-f7c50b1fccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "??fc.filter_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f324207-f94a-46cf-9b4e-ca0da37269d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = HooksCallback(append_stats, mod_filter=fc.risinstance(nn.Conv2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43add8cb-a535-4a87-b803-1c38e995ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "model = nn.Sequential(*cnn_layers())\n",
    "fit(model, xtra_cbs=[hc]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdb6f6-d726-43c1-ac3b-4cc2a161bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2, figsize=(10,4))\n",
    "for h in hc:\n",
    "    for i in 0,1: axs[i].plot(h.stats[i])\n",
    "plt.legend(range(6));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f8462-ed50-4f4e-a547-f02a1f0b4fdd",
   "metadata": {},
   "source": [
    "### **Histograms Viz for Layerwise Activations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5129478-8e1f-4e98-9cc4-b0663700eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_stats(hook, mod, inp, outp):\n",
    "    if not hasattr(hook, 'stats'): hook.stats = ([], [], [])\n",
    "    acts = to_cpu(outp)\n",
    "    hook.stats[0].append(acts.mean())\n",
    "    hook.stats[1].append(acts.std())\n",
    "    hook.stats[2].append(acts.abs().histc(40, 0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61abe98-33a8-43e3-a542-d0a5cfe62141",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "model = nn.Sequential(*cnn_layers())\n",
    "hc = HooksCallback(append_stats, mod_filter=fc.risinstance(nn.Conv2d))\n",
    "\n",
    "fit(model, xtra_cbs=[hc]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f883f6-eaa4-455c-b773-67abcc12e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get histogram\n",
    "def get_hist(h): return torch.stack(h.stats[2]).t().float().log1p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b56e78-ff78-4170-990d-18741784a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = get_grid(len(hc), figsize=(11, 5))\n",
    "\n",
    "for ax, h in zip(axes.flat, hc):\n",
    "    show_image(get_hist(h), ax, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a0e29-dc6e-4f8c-bcdb-b48d15a8a8cb",
   "metadata": {},
   "source": [
    "We also need to be able to visualize the number of dead neurons or failed activations within each layer to complement the histogram view above. The following function does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d13bd-d531-402b-a804-0db0b5963a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min(h):\n",
    "    h1 = torch.stack(h.stats[2]).t().float()\n",
    "    # Take the ratio of the bottom group with the total to get magnitudes\n",
    "    return h1[0]/h1.sum(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb12e8-1d29-466f-a7ea-8ad5b36c5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = get_grid(len(hc), figsize=(11,5))\n",
    "for ax,h in zip(axes.flatten(), hc):\n",
    "    ax.plot(get_min(h))\n",
    "    ax.set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c3dc97-b582-4e4e-b85b-32a639deb9e5",
   "metadata": {},
   "source": [
    "## **Composite ActivationStats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2e32d-ab8b-4287-b638-f213a417e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationStats(HooksCallback):\n",
    "    def __init__(self, mod_filter=fc.noop): super().__init__(append_stats, mod_filter)\n",
    "\n",
    "    def color_dim(self, figsize=(11, 5)):\n",
    "        fig, axes = get_grid(len(self), figsize=figsize)\n",
    "        for ax, h in zip(axes.flat, self):\n",
    "            show_image(get_hist(h), ax, origin='lower')\n",
    "\n",
    "    def dead_chart(self, figsize=(11, 5)):\n",
    "        fig, axes = get_grid(len(self), figsize=figsize)\n",
    "        for ax, h in zip(axes.flatten(), self):\n",
    "            ax.plot(get_min(h))\n",
    "            ax.set_ylim(0, 1)\n",
    "\n",
    "    def plot_stats(self, figsize=(10, 4)):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=figsize)\n",
    "        for h in self:\n",
    "            for i in 0, 1: axs[i].plot(h.stats[i])\n",
    "            axs[0].set_title('Means')\n",
    "            axs[1].set_title('Stdevs')\n",
    "            plt.legend(fc.L.range(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a7423-8b90-4e95-ba69-b4ddbd446561",
   "metadata": {},
   "outputs": [],
   "source": [
    "astats = ActivationStats(fc.risinstance(nn.Conv2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03637df-7c6c-4fd1-bfa2-64f931eeecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "model = nn.Sequential(*cnn_layers())\n",
    "fit(model, xtra_cbs=[astats]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7ecb6-a080-4f9e-9e22-cecab9b1a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "astats.color_dim();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff933b-1092-4ea9-bc6b-5beefad2f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "astats.dead_chart();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2a364-b4d9-4510-adee-74a31e4d6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "astats.plot_stats();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b75c01-d1ef-452d-acab-5bb74343d3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
