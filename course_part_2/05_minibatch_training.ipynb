{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f676cc4-bbd5-4440-b310-fcb1e385a28e",
   "metadata": {},
   "source": [
    "# **Mini Batch Training for MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c79cf2-95a9-442e-a250-b72d2f337628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip, math, os, time, shutil\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "from torch import tensor, nn\n",
    "import torch.nn.functional as F\n",
    "from fastcore.test import  test_close\n",
    "from pathlib import Path\n",
    "\n",
    "# Configs\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=3, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=3, linewidth=125)\n",
    "\n",
    "# Path setup\n",
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "# Loading MNIST data as tensors\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff73b2-644b-440e-b17d-e77da6044a76",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a1d4a-5b07-41e5-85e2-1b3942a0c4ca",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196455b3-48c1-468c-9169-8239bb421768",
   "metadata": {},
   "source": [
    "Copying over the starting cells from the previous NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0c897c-1bd8-45fd-b7c3-bf49501109e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50\n",
    "\n",
    "n, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cce843-3bae-41e6-95fe-ce2713be873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349c4b70-ee05-4966-b992-ee7374689db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh,  10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a952a6-ce01-4fce-9f43-1a48125b127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.091, -0.212, -0.082,  ..., -0.028,  0.006,  0.061],\n",
       "        [-0.073, -0.136, -0.143,  ...,  0.030,  0.043,  0.145],\n",
       "        [-0.186, -0.036,  0.018,  ..., -0.008, -0.003,  0.022],\n",
       "        ...,\n",
       "        [-0.026, -0.215, -0.038,  ..., -0.010,  0.090,  0.139],\n",
       "        [-0.099, -0.094, -0.046,  ..., -0.011,  0.018,  0.108],\n",
       "        [-0.033, -0.251, -0.064,  ...,  0.005,  0.030,  0.138]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114894b6-6128-4c2e-927f-a45d92fa3945",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e3b87-8ce6-4a6e-a393-b90c42ce010b",
   "metadata": {},
   "source": [
    "We need to improve our loss function from before. Instead of outputting 1 number per image, we will now have 10 one-hot-encoded numbers per image.\n",
    "\n",
    "The basic formula for Log Softmax is:\n",
    "\n",
    "$$\n",
    "\\log \\text{Softmax}(x_i) = \\log (\\frac{e^{x_i}}{\\sum_{x_j} e^{x_j}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb69627-8cd9-410f-b834-9db67fa003a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp() / (x.exp().sum(-1, keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a793025d-65b5-487c-8b91-88b9ae19661b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.373, -2.494, -2.364,  ..., -2.310, -2.276, -2.220],\n",
       "        [-2.372, -2.436, -2.442,  ..., -2.270, -2.257, -2.155],\n",
       "        [-2.480, -2.330, -2.275,  ..., -2.302, -2.297, -2.271],\n",
       "        ...,\n",
       "        [-2.329, -2.519, -2.342,  ..., -2.314, -2.214, -2.165],\n",
       "        [-2.382, -2.377, -2.329,  ..., -2.294, -2.265, -2.175],\n",
       "        [-2.329, -2.547, -2.360,  ..., -2.292, -2.266, -2.159]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad7d82-9266-426d-8371-8a4f2df983f7",
   "metadata": {},
   "source": [
    "Using the formula: $$ \\log\\left(\\frac{a}{b}\\right) = \\log(a) - \\log(b)$$ allows us to simplify the `log_softmax()` function further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30aea25b-d0d4-4b32-993c-5caecadb47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the log rule above and x.exp().log() = x since exp() and log() cancel out.\n",
    "def log_softmax(x): return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18c5f0-021d-4639-b7b0-bfa6f3a56fa1",
   "metadata": {},
   "source": [
    "Also, we can simplify things even further by using the [LogSumExp](https://en.wikipedia.org/wiki/LogSumExp) trick.\n",
    "\n",
    "This allows us to compute the log of the sum of exponentials in a more \"stable\" way i.e. it prevents numerical underflow or overflow when dealing with log probabilities. The mathematical representation for this is:\n",
    "\n",
    "$$\n",
    "\\log \\sum_{i} e^{x_i} = a + \\log \\sum_{i} e^{x_i - a}\n",
    "$$ \n",
    "\n",
    "where $a = \\max(x_i)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57afe8a4-b33b-468a-96d3-37b03378ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    # Taking the max on the last dim\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x - m[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b09f0b3-6e24-41cb-aea3-568463afe12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewriting log_softmax() using logsumexp() from PyTorch\n",
    "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d532b6fc-777a-4660-9587-e377626e4bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.373, -2.494, -2.364,  ..., -2.310, -2.276, -2.220],\n",
       "        [-2.372, -2.436, -2.442,  ..., -2.270, -2.257, -2.155],\n",
       "        [-2.480, -2.330, -2.275,  ..., -2.302, -2.297, -2.271],\n",
       "        ...,\n",
       "        [-2.329, -2.519, -2.342,  ..., -2.314, -2.214, -2.165],\n",
       "        [-2.382, -2.377, -2.329,  ..., -2.294, -2.265, -2.175],\n",
       "        [-2.329, -2.547, -2.360,  ..., -2.292, -2.266, -2.159]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
    "\n",
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1a09c-1ba3-4f6d-9e96-86af54fde523",
   "metadata": {},
   "source": [
    "So, the cross entropy loss can be rewritten as:\n",
    "\n",
    "$$\n",
    "- \\sum x \\log p(x)\n",
    "$$\n",
    "\n",
    "We can index into our 1-hot encoded x's using PyTorch's (and, NumPy's) advanced indexing methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b182ed25-ae42-4bef-9e57-4f52e46503cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's pick a sample\n",
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e70482-d00e-475d-8ddd-fe856dab33b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.200, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.372, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.355, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the positioning of the indices\n",
    "sm_pred[0, 5], sm_pred[1, 0], sm_pred[2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17d2bf08-1595-4978-a62a-8ca0bcb93370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.200, -2.372, -2.355], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The indexing method allows us to get these values as follows\n",
    "sm_pred[[0, 1, 2], y_train[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf8c44b-aca5-4b35-bc87-53d9aabe7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating negative log likelihood loss\n",
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9c3092e-6af7-4860-b19a-f2e311c3b38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.300, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f06609e4-e736-4e04-839f-e4b8513d260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch's version\n",
    "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63a61b-193b-4e60-a394-debc19db0a36",
   "metadata": {},
   "source": [
    "`F.log_softmax` and `F.nll_loss` are combined in one function called `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99465b6e-191d-40d8-839b-0aa2c0dfa684",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474341a-57d9-40f4-bf4d-2a758df71470",
   "metadata": {},
   "source": [
    "## Basic Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e92fd557-abd0-43f1-9477-9c8c01fddca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our loss function\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8224c0aa-f856-4bca-9f8f-86f9f42e91e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.091, -0.212, -0.082,  0.096, -0.035,  0.082, -0.042, -0.028,  0.006,  0.061], grad_fn=<SelectBackward0>),\n",
       " torch.Size([50, 10]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50               # batch size\n",
    "\n",
    "xb = x_train[0 : bs]  # Mini batch from training data\n",
    "preds = model(xb)     \n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "402e6fbc-73d2-4013-a23c-47b3bb782b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7,\n",
       "        6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking our target, matching the mini-batch size\n",
    "yb = y_train[0 : bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6af71020-c66a-4daa-b4c4-280f2522bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.305, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the loss function\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96825fe-ac46-400b-9bbd-933d4e07d998",
   "metadata": {},
   "source": [
    "Lets find the index of the highest number for each of our 64 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9898f02a-d345-42dd-aa4e-164aa4484f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3,\n",
       "        9, 3, 5, 3, 8, 3, 5, 9, 5, 9, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee7f3497-9fdc-4e2c-a6db-abcf92d13e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.080)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the accuracy of our predictions\n",
    "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()\n",
    "\n",
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ba660fd-d1e2-4f99-b376-11bde0300159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a learning rate and number of epochs\n",
    "lr = 0.5\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4176e717-4661-4567-afbe-6dbffe73a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print loss and accuracy after each epoch\n",
    "def report(loss, preds, yb): print(f'{loss:.3f}, {accuracy(preds, yb):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b460bd3-1b88-422b-b512-b0f8c6b18211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.305, 0.080\n"
     ]
    }
   ],
   "source": [
    "xb, yb = x_train[:bs], y_train[:bs]\n",
    "preds = model(xb)\n",
    "report(loss_func(preds, yb), preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6272f4b8-986c-48a7-ab11-53a2f632a883",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115, 0.980\n",
      "0.124, 0.940\n",
      "0.082, 0.960\n"
     ]
    }
   ],
   "source": [
    "# Our training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs)) # Create a slice from x_i to x_n or equivalent to bs\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        # Backward pass\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_() #inplace zeroing\n",
    "                    l.bias  .grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed494f-46c8-451c-90f4-2c72e4462207",
   "metadata": {},
   "source": [
    "## Using Parameters and Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e2054-9b39-4d16-84f6-d1bf7b650154",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Lets rebuild the `nn.Module` class to get a better understanding of whats going on under the hood before implementing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5f018db-6c2f-4e13-94cd-e3596393dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using PyTorch's nn.Module class and assigning an attribute which is a linear layer\n",
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(in_features=3, out_features=4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a6daa-0584-41e6-b741-fc4603293341",
   "metadata": {},
   "source": [
    "We can see each of the items or `named_children` (which is an generator function) in the module as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d06ec6f-7694-481f-ac9d-f86cbf12d2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066e7d3-6637-4b46-817b-d66e66b4ec85",
   "metadata": {},
   "source": [
    "We can list the parameters of the module as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "640c9552-a7a4-4e1c-b09d-c389d0c39118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.568,  0.431, -0.300],\n",
       "         [ 0.126, -0.321, -0.238],\n",
       "         [ 0.508,  0.038,  0.218],\n",
       "         [ 0.131, -0.170, -0.237]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.011, -0.511, -0.392,  0.560], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a3aa4-eda8-4dcf-ba0a-a7d248966192",
   "metadata": {},
   "source": [
    "So, this makes it possible for the `nn.Module` class to inherit attributes when we create model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45fcff00-8f62-4d84-939b-cb47ad74a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # Inputs, outputs and a single NH layer\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    # As before, we will use the refactore forward() function instead of __call()__ to let\n",
    "    # PyTorch handle all gradient calcs.\n",
    "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c80c6736-9c30-438c-8d81-30c6d26633ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling each layer of the model.\n",
    "model = MLP(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42b5a6ae-fe46-4e01-9ccb-48d4d633e551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "# Listing all the attributes\n",
    "for name, l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eeabc137-c12e-43ee-84bd-2c1dc64f6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# And listing all the parameters\n",
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5667684-6d33-43bf-8117-b5087e1e563c",
   "metadata": {},
   "source": [
    "Since PyTorch can handle all the attributes and parameters for us, we can rewrite the training loop from the earlier section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cadf4ae-b56e-441c-8c84-ad18cb743a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "# Training loop as a function\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            #pdb.set_trace()\n",
    "            s = slice(i, min(n, i+bs))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            #Updated section, we no longer need to explicitly call each layer's updates\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "885bcc11-57f0-4e49-b6b8-a0a0fef5bd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.187, 0.960\n",
      "0.112, 0.960\n",
      "0.045, 1.000\n"
     ]
    }
   ],
   "source": [
    "# Running the training loop function\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f263ff-ec2b-48b0-855d-1c70657de940",
   "metadata": {},
   "source": [
    "The inheritance class makes things extremely streamlined when constructing models, but how does it really work its magic?\n",
    "\n",
    "At the heart of the action is PyTorch overriding the `__setattr__` function in `nn.Module`. Python documentation defines it as:\n",
    "\n",
    "> This is the counterpart of `getattr()`. The arguments are an object, a string, and an arbitrary value. The string may name an existing attribute or a new attribute. The function assigns the value to the attribute, provided the object allows it. For example, `setattr(x, 'foobar', 123)` is equivalent to `x.foobar = 123`.\n",
    "\n",
    "Lets rebuild `nn.Module` as a demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de5febca-8f24-4310-b806-cb1aab30a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {} # Dictionary for storing named children\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __setattr__(self, k, v): # Automatically called when we set attributes in the class\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v) # Ensure attributes are set\n",
    "\n",
    "    def __repr__(self): return f'{self._modules}' # Return string of dict\n",
    "\n",
    "    def parameters(self):\n",
    "        # We can use the yield shortcut to return values from an iterator instead of looping through it.\n",
    "        for l in self._modules.values(): yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44078e9a-c38b-4b9b-866c-c1c0cff56675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = MyModule(m, nh, 10)\n",
    "mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ccfda-72da-4ed2-a599-64632216b74d",
   "metadata": {},
   "source": [
    "The rest of the functionality works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdc49aed-f9fc-482d-9a2a-f929fe0a85c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mod.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b222ff-08b3-4e46-9e1b-334c584db912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847b1a2-55a0-44e6-92fe-3b5cef9eb3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a60f2-9862-4c15-9c25-79b4539c12bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb15ab-876a-417d-8f43-6051cf356737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b1dff-f69e-4e9b-9e5e-b177596a0e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e420a-bd53-4c51-9bdc-82cb0b1a398c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e303f-0330-4f1b-9fbf-14fc55660e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b928a1b-b096-4bd8-8deb-39daaef56590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
