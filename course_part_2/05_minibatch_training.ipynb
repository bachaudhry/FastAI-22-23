{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f676cc4-bbd5-4440-b310-fcb1e385a28e",
   "metadata": {},
   "source": [
    "# **Mini Batch Training for MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "34c79cf2-95a9-442e-a250-b72d2f337628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip, math, os, time, shutil\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor, nn\n",
    "import torch.nn.functional as F\n",
    "from fastcore.test import  test_close\n",
    "from pathlib import Path\n",
    "\n",
    "# Configs\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=3, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=3, linewidth=125)\n",
    "\n",
    "# Path setup\n",
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "# Loading MNIST data as tensors\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff73b2-644b-440e-b17d-e77da6044a76",
   "metadata": {},
   "source": [
    "## **Initial Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a1d4a-5b07-41e5-85e2-1b3942a0c4ca",
   "metadata": {},
   "source": [
    "### **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196455b3-48c1-468c-9169-8239bb421768",
   "metadata": {},
   "source": [
    "Copying over the starting cells from the previous NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0c897c-1bd8-45fd-b7c3-bf49501109e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50\n",
    "\n",
    "n, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cce843-3bae-41e6-95fe-ce2713be873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349c4b70-ee05-4966-b992-ee7374689db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh,  10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a952a6-ce01-4fce-9f43-1a48125b127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.091, -0.212, -0.082,  ..., -0.028,  0.006,  0.061],\n",
       "        [-0.073, -0.136, -0.143,  ...,  0.030,  0.043,  0.145],\n",
       "        [-0.186, -0.036,  0.018,  ..., -0.008, -0.003,  0.022],\n",
       "        ...,\n",
       "        [-0.026, -0.215, -0.038,  ..., -0.010,  0.090,  0.139],\n",
       "        [-0.099, -0.094, -0.046,  ..., -0.011,  0.018,  0.108],\n",
       "        [-0.033, -0.251, -0.064,  ...,  0.005,  0.030,  0.138]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114894b6-6128-4c2e-927f-a45d92fa3945",
   "metadata": {},
   "source": [
    "### **Cross Entropy Loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e3b87-8ce6-4a6e-a393-b90c42ce010b",
   "metadata": {},
   "source": [
    "We need to improve our loss function from before. Instead of outputting 1 number per image, we will now have 10 one-hot-encoded numbers per image.\n",
    "\n",
    "The basic formula for Log Softmax is:\n",
    "\n",
    "$$\n",
    "\\log \\text{Softmax}(x_i) = \\log (\\frac{e^{x_i}}{\\sum_{x_j} e^{x_j}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb69627-8cd9-410f-b834-9db67fa003a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp() / (x.exp().sum(-1, keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a793025d-65b5-487c-8b91-88b9ae19661b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.373, -2.494, -2.364,  ..., -2.310, -2.276, -2.220],\n",
       "        [-2.372, -2.436, -2.442,  ..., -2.270, -2.257, -2.155],\n",
       "        [-2.480, -2.330, -2.275,  ..., -2.302, -2.297, -2.271],\n",
       "        ...,\n",
       "        [-2.329, -2.519, -2.342,  ..., -2.314, -2.214, -2.165],\n",
       "        [-2.382, -2.377, -2.329,  ..., -2.294, -2.265, -2.175],\n",
       "        [-2.329, -2.547, -2.360,  ..., -2.292, -2.266, -2.159]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad7d82-9266-426d-8371-8a4f2df983f7",
   "metadata": {},
   "source": [
    "Using the formula: $$ \\log\\left(\\frac{a}{b}\\right) = \\log(a) - \\log(b)$$ allows us to simplify the `log_softmax()` function further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30aea25b-d0d4-4b32-993c-5caecadb47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the log rule above and x.exp().log() = x since exp() and log() cancel out.\n",
    "def log_softmax(x): return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18c5f0-021d-4639-b7b0-bfa6f3a56fa1",
   "metadata": {},
   "source": [
    "Also, we can simplify things even further by using the [LogSumExp](https://en.wikipedia.org/wiki/LogSumExp) trick.\n",
    "\n",
    "This allows us to compute the log of the sum of exponentials in a more \"stable\" way i.e. it prevents numerical underflow or overflow when dealing with log probabilities. The mathematical representation for this is:\n",
    "\n",
    "$$\n",
    "\\log \\sum_{i} e^{x_i} = a + \\log \\sum_{i} e^{x_i - a}\n",
    "$$ \n",
    "\n",
    "where $a = \\max(x_i)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57afe8a4-b33b-468a-96d3-37b03378ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    # Taking the max on the last dim\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x - m[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b09f0b3-6e24-41cb-aea3-568463afe12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewriting log_softmax() using logsumexp() from PyTorch\n",
    "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d532b6fc-777a-4660-9587-e377626e4bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.373, -2.494, -2.364,  ..., -2.310, -2.276, -2.220],\n",
       "        [-2.372, -2.436, -2.442,  ..., -2.270, -2.257, -2.155],\n",
       "        [-2.480, -2.330, -2.275,  ..., -2.302, -2.297, -2.271],\n",
       "        ...,\n",
       "        [-2.329, -2.519, -2.342,  ..., -2.314, -2.214, -2.165],\n",
       "        [-2.382, -2.377, -2.329,  ..., -2.294, -2.265, -2.175],\n",
       "        [-2.329, -2.547, -2.360,  ..., -2.292, -2.266, -2.159]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
    "\n",
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1a09c-1ba3-4f6d-9e96-86af54fde523",
   "metadata": {},
   "source": [
    "So, the cross entropy loss can be rewritten as:\n",
    "\n",
    "$$\n",
    "- \\sum x \\log p(x)\n",
    "$$\n",
    "\n",
    "We can index into our 1-hot encoded x's using PyTorch's (and, NumPy's) advanced indexing methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b182ed25-ae42-4bef-9e57-4f52e46503cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's pick a sample\n",
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e70482-d00e-475d-8ddd-fe856dab33b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.200, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.372, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.355, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the positioning of the indices\n",
    "sm_pred[0, 5], sm_pred[1, 0], sm_pred[2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17d2bf08-1595-4978-a62a-8ca0bcb93370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.200, -2.372, -2.355], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The indexing method allows us to get these values as follows\n",
    "sm_pred[[0, 1, 2], y_train[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf8c44b-aca5-4b35-bc87-53d9aabe7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating negative log likelihood loss\n",
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9c3092e-6af7-4860-b19a-f2e311c3b38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.300, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f06609e4-e736-4e04-839f-e4b8513d260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch's version\n",
    "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63a61b-193b-4e60-a394-debc19db0a36",
   "metadata": {},
   "source": [
    "`F.log_softmax` and `F.nll_loss` are combined in one function called `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99465b6e-191d-40d8-839b-0aa2c0dfa684",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474341a-57d9-40f4-bf4d-2a758df71470",
   "metadata": {},
   "source": [
    "## **Basic Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e92fd557-abd0-43f1-9477-9c8c01fddca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our loss function\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8224c0aa-f856-4bca-9f8f-86f9f42e91e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.091, -0.212, -0.082,  0.096, -0.035,  0.082, -0.042, -0.028,  0.006,  0.061], grad_fn=<SelectBackward0>),\n",
       " torch.Size([50, 10]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50               # batch size\n",
    "\n",
    "xb = x_train[0 : bs]  # Mini batch from training data\n",
    "preds = model(xb)     \n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "402e6fbc-73d2-4013-a23c-47b3bb782b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7,\n",
       "        6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking our target, matching the mini-batch size\n",
    "yb = y_train[0 : bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6af71020-c66a-4daa-b4c4-280f2522bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.305, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the loss function\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96825fe-ac46-400b-9bbd-933d4e07d998",
   "metadata": {},
   "source": [
    "Lets find the index of the highest number for each of our 64 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9898f02a-d345-42dd-aa4e-164aa4484f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3,\n",
       "        9, 3, 5, 3, 8, 3, 5, 9, 5, 9, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee7f3497-9fdc-4e2c-a6db-abcf92d13e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.080)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the accuracy of our predictions\n",
    "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()\n",
    "\n",
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ba660fd-d1e2-4f99-b376-11bde0300159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a learning rate and number of epochs\n",
    "lr = 0.5\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4176e717-4661-4567-afbe-6dbffe73a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print loss and accuracy after each epoch\n",
    "def report(loss, preds, yb): print(f'{loss:.3f}, {accuracy(preds, yb):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b460bd3-1b88-422b-b512-b0f8c6b18211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.305, 0.080\n"
     ]
    }
   ],
   "source": [
    "xb, yb = x_train[:bs], y_train[:bs]\n",
    "preds = model(xb)\n",
    "report(loss_func(preds, yb), preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6272f4b8-986c-48a7-ab11-53a2f632a883",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115, 0.980\n",
      "0.124, 0.940\n",
      "0.082, 0.960\n"
     ]
    }
   ],
   "source": [
    "# Our training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs)) # Create a slice from x_i to x_n or equivalent to bs\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        # Backward pass\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_() #inplace zeroing\n",
    "                    l.bias  .grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed494f-46c8-451c-90f4-2c72e4462207",
   "metadata": {},
   "source": [
    "## **Using Parameters and Optim**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e2054-9b39-4d16-84f6-d1bf7b650154",
   "metadata": {},
   "source": [
    "### **Parameters**\n",
    "\n",
    "Lets rebuild the `nn.Module` class to get a better understanding of whats going on under the hood before implementing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5f018db-6c2f-4e13-94cd-e3596393dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using PyTorch's nn.Module class and assigning an attribute which is a linear layer\n",
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(in_features=3, out_features=4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a6daa-0584-41e6-b741-fc4603293341",
   "metadata": {},
   "source": [
    "We can see each of the items or `named_children` (which is an generator function) in the module as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d06ec6f-7694-481f-ac9d-f86cbf12d2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066e7d3-6637-4b46-817b-d66e66b4ec85",
   "metadata": {},
   "source": [
    "We can list the parameters of the module as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "640c9552-a7a4-4e1c-b09d-c389d0c39118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.568,  0.431, -0.300],\n",
       "         [ 0.126, -0.321, -0.238],\n",
       "         [ 0.508,  0.038,  0.218],\n",
       "         [ 0.131, -0.170, -0.237]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.011, -0.511, -0.392,  0.560], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a3aa4-eda8-4dcf-ba0a-a7d248966192",
   "metadata": {},
   "source": [
    "So, this makes it possible for the `nn.Module` class to inherit attributes when we create model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45fcff00-8f62-4d84-939b-cb47ad74a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # Inputs, outputs and a single NH layer\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    # As before, we will use the refactore forward() function instead of __call()__ to let\n",
    "    # PyTorch handle all gradient calcs.\n",
    "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c80c6736-9c30-438c-8d81-30c6d26633ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling each layer of the model.\n",
    "model = MLP(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42b5a6ae-fe46-4e01-9ccb-48d4d633e551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "# Listing all the attributes\n",
    "for name, l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eeabc137-c12e-43ee-84bd-2c1dc64f6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# And listing all the parameters\n",
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5667684-6d33-43bf-8117-b5087e1e563c",
   "metadata": {},
   "source": [
    "Since PyTorch can handle all the attributes and parameters for us, we can rewrite the training loop from the earlier section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cadf4ae-b56e-441c-8c84-ad18cb743a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "# Training loop as a function\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            #pdb.set_trace()\n",
    "            s = slice(i, min(n, i+bs))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            #Updated section, we no longer need to explicitly call each layer's updates\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "885bcc11-57f0-4e49-b6b8-a0a0fef5bd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.187, 0.960\n",
      "0.112, 0.960\n",
      "0.045, 1.000\n"
     ]
    }
   ],
   "source": [
    "# Running the training loop function\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f263ff-ec2b-48b0-855d-1c70657de940",
   "metadata": {},
   "source": [
    "The inheritance class makes things extremely streamlined when constructing models, but how does it really work its magic?\n",
    "\n",
    "At the heart of the action is PyTorch overriding the `__setattr__` function in `nn.Module`. Python documentation defines it as:\n",
    "\n",
    "> This is the counterpart of `getattr()`. The arguments are an object, a string, and an arbitrary value. The string may name an existing attribute or a new attribute. The function assigns the value to the attribute, provided the object allows it. For example, `setattr(x, 'foobar', 123)` is equivalent to `x.foobar = 123`.\n",
    "\n",
    "Lets rebuild `nn.Module` as a demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de5febca-8f24-4310-b806-cb1aab30a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule: # Not having () after the class name is equivalent to calling MyModule(object)\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {} # Dictionary for storing named children\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __setattr__(self, k, v): # Automatically called when we set attributes in the class\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v) # Ensure attributes are set\n",
    "\n",
    "    def __repr__(self): return f'{self._modules}' # Return string of dict\n",
    "\n",
    "    def parameters(self):\n",
    "        # We can use the yield shortcut to return values from an iterator instead of looping through it.\n",
    "        for l in self._modules.values(): yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44078e9a-c38b-4b9b-866c-c1c0cff56675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = MyModule(m, nh, 10)\n",
    "mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ccfda-72da-4ed2-a599-64632216b74d",
   "metadata": {},
   "source": [
    "The rest of the functionality works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdc49aed-f9fc-482d-9a2a-f929fe0a85c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mod.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387f519-952d-4c7d-a94a-2777de121650",
   "metadata": {},
   "source": [
    "Now that we have successfully recreated `nn.Module`, we will also need to save or _register_ the various layers of our model. This needs to happen all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9745a-5140-4170-934c-9e1f50c472f0",
   "metadata": {},
   "source": [
    "### **Registering Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e6a60f2-9862-4c15-9c25-79b4539c12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753d97b-4c67-4100-a2bc-7287dd79899c",
   "metadata": {},
   "source": [
    "Lets create a list of all the layers of our model, which we can then pass to a subclass of `nn.Module` i.e. `Model`. This approach is generally used to build sequential models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef5b1dff-f69e-4e9b-9e5e-b177596a0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f41e420a-bd53-4c51-9bdc-82cb0b1a398c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers # Store the list of layers\n",
    "        for i, l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "\n",
    "    def forward(self, x): return reduce(lambda val, layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "428e303f-0330-4f1b-9fbf-14fc55660e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reference\n",
    "reduce(lambda x, y: x+y, [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b928a1b-b096-4bd8-8deb-39daaef56590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6041426-cef1-40ae-8a0a-e84d874f6a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592007f-b389-4c87-b31e-1a728e6b2ebd",
   "metadata": {},
   "source": [
    "### **nn.ModuleList**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2423d73-f65e-4829-980b-1fb729741f5f",
   "metadata": {},
   "source": [
    "Passing the list of Layers is already handled by `nn.ModuleList`. Reverting to PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "851f889b-e36d-422f-9992-8a8e6f36a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x): # Reductions: reduce() works the same as this block, and is widely used for sequential models\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "678cac11-b74a-43e8-b6bb-7df45f965d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9f0774e-7d59-436b-bf09-db5c5442cc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.119, 0.960\n",
      "0.109, 0.960\n",
      "0.075, 0.980\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9472d-3db4-449f-8f8b-de684fecdaa9",
   "metadata": {},
   "source": [
    "### **nn.Sequential**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12aec7-f5c0-4dba-907d-7182fe414231",
   "metadata": {},
   "source": [
    "`Sequential` has also been recreated above, so we can revert to PyTorch's `nn.Sequential` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e467f96-1cc8-4978-b6b5-150037355962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5988fe57-b60b-4799-81ad-2de4bcf81176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.164, 0.940\n",
      "0.128, 0.960\n",
      "0.076, 0.960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.026, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ad7d638-a227-4a3b-a9b0-2ad1cfeadd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfbb804-f73e-4c1c-bc29-cfe9f91160b9",
   "metadata": {},
   "source": [
    "### **Optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e427e3a-8e4d-455c-a7fa-42117f58f9d0",
   "metadata": {},
   "source": [
    "The `Optimizer` cycles through the parameters and updates them using the gradients and the learning rate. This class also sets the gradients to zero after each backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dfbf98ec-b603-4667-9305-7731d6f982ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): self.params, self.lr = list(params), lr # Since params might be a generator\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33db8c71-8240-47e8-8ae2-2f4564bcb323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model using Sequential from before.\n",
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "# Creating the optimizer\n",
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fb8c58a5-de40-4027-bb67-f6c4e98cbe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.175, 0.960\n",
      "0.116, 0.980\n",
      "0.088, 0.980\n"
     ]
    }
   ],
   "source": [
    "# Here's an even more updated version of the training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        # Updates \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799eaa60-f396-4421-a983-0e3ef3f5bc00",
   "metadata": {},
   "source": [
    "At this point, we've effectively created an `SGD` optimizer. That means we can use PyTorch's version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c02120c0-4b30-48de-be1c-6600f9bc23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b8e160bb-65b0-44e5-8fb0-832d25f87b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "    # Passing the model's parameters to PyTorch's SGD optimizer\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3ccdeb30-7a31-42b6-b516-712870be71d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.295, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5a1e7e7e-64e6-414b-a089-b74d7256e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.114, 0.980\n",
      "0.092, 0.980\n",
      "0.058, 1.000\n"
     ]
    }
   ],
   "source": [
    "# Re-running the training loop again, this time Pytorch has us covered with its classes for the model and optim.\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d89f21-54e8-49cf-a308-c2e85c2a8f75",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The code could do with additional refactoring, especially where data handling is concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f8243-56f5-46d2-a65f-e1441d24d304",
   "metadata": {},
   "source": [
    "## **Dataset and DataLoader**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b146b-7fff-4c31-b6ce-5f6372e102a1",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0bfe8f-585d-4028-95f6-f44acb0617a2",
   "metadata": {},
   "source": [
    "Handling minibatches of x and y values separately is not optimal. A class which handles mini-batches and additional data related functionality is the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db4d445a-c96a-4390-92c8-7a33947fcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    \n",
    "    def __len__(self ): return len(self.x) # Length of the dataset\n",
    "\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i] # Grab items, return a tuple of (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ae68044d-7daa-4810-8e79-580489c0e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataset\n",
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "# Ensuring the sizes match\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6059a366-2bd5-4f96-805b-0d3ff50d2ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([50000]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4a737e5c-4948-4abe-b757-850f2af79e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([50000]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feeding in the entire data set gives us\n",
    "xb, yb = train_ds[:]\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "df94f6b5-3fd6-47ef-b653-1c06c974cb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking a much smaller sample\n",
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape == (5, 28*28)\n",
    "assert yb.shape == (5,)\n",
    "\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af290c-ac52-4373-abe8-207db10a9241",
   "metadata": {},
   "source": [
    "PyTorch also handles datasets this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "98bdad33-7f5d-4a01-9f79-53a5b83ef541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.110, 0.980\n",
      "0.074, 1.000\n",
      "0.081, 0.980\n"
     ]
    }
   ],
   "source": [
    "# Creating the model again\n",
    "model, opt = get_model()\n",
    "\n",
    "# Re-running the training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        # Updated data handling\n",
    "        xb, yb = train_ds[i : min(n, i+bs)]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac073a-4ec8-4d54-bad0-57b6a4728bbf",
   "metadata": {},
   "source": [
    "The for loop handling the data loading part of the loop can also be refactored away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b75ed4-5861-44a3-8504-6c27be34fba8",
   "metadata": {},
   "source": [
    "### **DataLoader**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f645387-35b9-409a-808d-d58c4d029190",
   "metadata": {},
   "source": [
    "Instead of looping over batches, we can use a dataloader to further simplify the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4edc6690-4f12-403f-9072-1cd722069655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds, bs\n",
    "\n",
    "    def __iter__(self): # The iterator handles looping through the batches and items.\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d17c7922-b20f-4181-8f66-7d87bec2ffdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.DataLoader at 0x7f34870bf100>,\n",
       " <__main__.DataLoader at 0x7f34a0aa7ca0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)\n",
    "\n",
    "train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b29c3f7f-03a6-4da2-b418-6c181886fffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl)) # Iterate through the dataloader object and grab items \n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b68550d-d6c8-46da-b7fc-551ebdf8916c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 6, 9, 6, 4, 5, 3, 8, 4, 5, 2, 3, 8, 4, 8, 1, 5, 0, 5, 9, 7, 4, 1, 0, 3, 0, 6, 2, 9, 9, 4, 1, 3, 6, 8, 0, 7, 7,\n",
       "        6, 8, 9, 0, 3, 8, 3, 7, 7, 8, 4])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking yb\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a70ec404-ed1c-4a7c-bd5b-dea47d3d3ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the first element of the x batch\n",
    "plt.imshow(xb[0].view(28, 28));\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "96d7a5d6-e099-41bc-bfa3-bf828fcb653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, reloading the model, the optim and updating the training loop with the new \n",
    "# dataloader implementation\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl: # Already loaded\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4e70b973-3a49-4f33-aaec-5c59104a7928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.076, 0.980\n",
      "0.057, 0.980\n",
      "0.050, 0.980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.045, grad_fn=<NllLossBackward0>), tensor(0.960))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771af35b-1873-4841-a010-5c4f1cd7f5f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
